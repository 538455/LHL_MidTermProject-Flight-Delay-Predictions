{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd89ca15-6b96-491f-b08e-7a7cb850967d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Function Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fd4687-871c-4a5c-aa42-7e84b8ef7544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataCleaning(df, code=True, tips=False, orientation=True, formatIssues=True, missingValues=True, duplicateValues=True, outliers=True):\n",
    "    \"\"\"\n",
    "    df: your dataframe\n",
    "\n",
    "    code: A text template to note your observations as you go. Use the code snippets included in the output. copy-paste into vscode/notepad\n",
    "\n",
    "    tips: Provides snippets of code to help you clean potential issues in your df. If you prefer this to code\n",
    "    \n",
    "    orientation: Provides information about the shape/objects of your data\n",
    "    \n",
    "    formatIssues: Provides detailed information on each column to help identify format issues\n",
    "    \n",
    "    missingValues: Provides information on missing values\n",
    "    \n",
    "    duplicateValues: Provides information on duplicate values\n",
    "    \n",
    "    outliers: Provides information on outliers\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    if code==True:\n",
    "        print(\"### CLEANING CODE:\")\n",
    "        print(\"df = dfX #Change to your df's name\")\n",
    "        print()\n",
    "        print(\"#### Change column value:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Drop entire column:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Change column type:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Change column name:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Handle missing values:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Handle duplicate values:\")\n",
    "        print(\"# df.drop_duplicates(inplace=True) # drop ALL duplicate rows\")\n",
    "        print()\n",
    "        print(\"#### Drop outliers:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Other observations / further investigations:\")\n",
    "        print(\"#\")\n",
    "        print(\"#\")\n",
    "        print(\"#\")\n",
    "        print()\n",
    "        print(\"df.head() #Final Review\")\n",
    "        print(\"# dfX = df #Change to your df's name\")\n",
    "        print()\n",
    "        print(\"=========================================\")\n",
    "    \n",
    "    if orientation==True:\n",
    "        print(\"ORIENTATION\")\n",
    "        print(df.info())\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    if formatIssues==True:\n",
    "        print(\"FORMAT ISSUES\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object' or df[col].dtype == 'int64' or df[col].dtype == 'float64' or df[col].dtype == 'datetime64':\n",
    "            #if df[col].dtype == 'float64':\n",
    "\n",
    "                print(\"df.rename(columns={'\" + col + \"': ''}, inplace=True)\", \"#rename column\")\n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].replace('old_value', 'new_value')\")\n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].astype('new_type') # new_type can be int64, float64, object, category, datetime64\")\n",
    "                print(\"df.drop('\" + col + \"', axis=1, inplace=True)\")                \n",
    "                pd.set_option('display.max_rows', None)\n",
    "                print(df.groupby(col, sort=True).size())\n",
    "                pd.reset_option('display.max_rows')\n",
    "                #display the dtypes of the column\n",
    "                print(\"Current Column DType: \", df[col].dtype, \"     Do not compare with above. This one will always return int64 as it's the dtype of the count\")                \n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].astype('new_type') # new_type can be int64, float64, object, category, datetime64\")\n",
    "                print()\n",
    "            #else:\n",
    "            #    print(col)\n",
    "            #    print(df[col].describe())\n",
    "            #    print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"To make a correction to a column, use the following syntax:\")\n",
    "            print(\"df['A'] = df['A'].apply(lambda x: x.replace('old_value', 'new_value'))\")\n",
    "            print()\n",
    "            print(\"To change a column data type, use the following syntax:\")\n",
    "            print(\"df['A'] = pd.to_datetime(df['A']) # for datetime\")\n",
    "            print(\"df['A'] = df['A'].astype('int64') # for integers\")\n",
    "            print(\"df['A'] = df['A'].astype('float64') # for floats\")\n",
    "            print(\"df['A'] = df['A'].astype('category') # for categorical\")\n",
    "            print(\"df['A'] = df['A'].astype('object') # for object\")\n",
    "            print()\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if missingValues==True:\n",
    "        print(\"MISSING VALUES\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                print(col, \":\", df[col].isnull().sum(), \" missing values\")\n",
    "                print(\"df.dropna(subset=['\" + col + \"'], inplace=True)\")\n",
    "                print(\"df['\" + col + \"'].fillna(df['\" + col + \"'].mean(), inplace=True) #fill NA entries with the mean\")\n",
    "                print(\"df['\" + col + \"'].fillna(0, inplace=True) # fill NA entries with a single value, such as zero\")\n",
    "                print()\n",
    "                print(df.loc[df[col].isnull()].head())\n",
    "                print()\n",
    "            else:\n",
    "                print(col, \": No missing values\")\n",
    "                print()\n",
    "                                    \n",
    "        if tips==True:\n",
    "            print()\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop rows with missing values using one of the following code:\")\n",
    "            print(\"df.dropna(subset=['col'], inplace=True) #For a single column\")\n",
    "            print(\"df.dropna(inplace=True) #For all columns\")\n",
    "            print()\n",
    "            print(\"You can fill rows with missing values using one of the following code:\")\n",
    "            print(\"df['col'].fillna(df['col'].mean(), inplace=True) #fill NA entries with the mean\")\n",
    "            print(\"df['col'].fillna(0, inplace=True) # fill NA entries with a single value, such as zero\")\n",
    "            print(\"df['col'].fillna(method='ffill') # forward-fill to propagate the previous value forward\")\n",
    "            print(\"df['col'].fillna(method='bfill' # back-fill to propagate the next values backward)\")\n",
    "            print()\n",
    "            print(\"To view them:\")\n",
    "            print(\"df.loc[df[col].isnull()].head()\")\n",
    "            print()\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if duplicateValues==True:\n",
    "        print(\"DUPLICATE VALUES\")\n",
    "        print()\n",
    "        print(df[df.duplicated()].head())\n",
    "        print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop duplicate rows using the following code:\")\n",
    "            print(\"df.drop_duplicates(inplace=True)\")\n",
    "            print(\"df.drop_duplicates(subset=['col'], inplace=True) #For a single column\")\n",
    "            print()\n",
    "            print(\"To view them:\")\n",
    "            print(\"df[df.duplicated()].head()\")\n",
    "            print()\n",
    "    \n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if outliers==True:\n",
    "        print(\"OUTLIERS\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'int64' or df[col].dtype == 'float64':\n",
    "                print(col)\n",
    "                print(\"-----\")\n",
    "                print(\"Outlier(s):\")\n",
    "                print(\"Below \", df[col].mean() - 3*df[col].std(), \" -> \", df[df[col] < df[col].mean() - 3*df[col].std()].shape[0], \" low outlier(s)\")\n",
    "                print(\"Above \", df[col].mean() + 3*df[col].std(), \" -> \", df[df[col] > df[col].mean() + 3*df[col].std()].shape[0], \" high outlier(s)\")\n",
    "                low = df[col].mean() - 3*df[col].std()\n",
    "                high = df[col].mean() + 3*df[col].std()\n",
    "                print(\"df = df[(df['\" + col + \"'] > \" + str(low) + \") & (df['\" + col + \"'] < \" + str(high) + \")]\")\n",
    "                print()\n",
    "                print(df[col].describe())\n",
    "                print()\n",
    "                print(\"Boxplot\")\n",
    "                sns.boxplot(df[col])\n",
    "                plt.show()\n",
    "                print()\n",
    "                print(\"Histogram\")\n",
    "                sns.histplot(df[col])\n",
    "                plt.show()\n",
    "                print(\"=========================================\")\n",
    "                print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop outliers using the following code:\")\n",
    "            print(\"df = df[(df['column'] > lower_bound) & (df['column'] < upper_bound)]\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48072217-c0ed-4657-9610-c3cca8d87556",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cd2116-e279-405d-a4e9-b48c6dabb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea2ce1c-0b79-4965-b838-8cf4e962db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_sample = pd.read_csv(\"../../data/raw/flights_sample+test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964e2e5e-18a9-4695-9682-22c0f9e331e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed(29Nov).csv\") \n",
    "## In the first step noticed this was not properly done (see Take 1 - Archived) so made the new one below.\n",
    "## Uncomment above and switch the cells in Take 1 archived to code for further details\n",
    "\n",
    "passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed_groupedbyMonth(29Nov).csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89cad7a9-3341-4787-af79-0f738b8fce02",
   "metadata": {},
   "source": [
    "passengers:\n",
    "\n",
    "This CSV was produced using the following SQL Query on the passengers table:\n",
    "\n",
    "SELECT CONCAT(year, '_', month, '-', unique_carrier, '-', origin, '-', dest) AS routeId\n",
    "\t, payload / departures_performed AS averagePayload_lbs\n",
    "\t, freight / departures_performed AS averageFreight_lbs\n",
    "\t, mail / departures_performed AS averageMail_lbs\n",
    "\t, seats / departures_performed AS availableSeats\n",
    "\t, passengers / departures_performed AS averagePassengers\n",
    "\t--, passengers / seats * 100 AS averageSeatsoccupied_perc\n",
    "\t, aircraft_group AS aircraftGroup\n",
    "\t, aircraft_type AS aircraftType\n",
    "\t, aircraft_config AS aircraftConfiguration\n",
    "\t, distance_group AS distanceInterval_x500mi\n",
    "\t, class AS serviceClass\n",
    "FROM passengers\n",
    "WHERE departures_performed > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387dac4-524f-4ed7-a30f-204fff3084c5",
   "metadata": {},
   "source": [
    "# Deciding on the Route ID column (will be used to merge with flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c045-9227-414a-9931-72f564c2d766",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Take 1 (dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7896b38-87b6-4d55-917f-8ce045807362",
   "metadata": {},
   "source": [
    "The passengers table is huge, it likely has information on routes that we don't need. Let's slim it down"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5278731d-1546-4a44-8722-cbb6b9e5721d",
   "metadata": {},
   "source": [
    "passengers.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1dacb895-7fa3-403f-9f1d-48fceb362979",
   "metadata": {},
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Flight Year'].astype(str) + '_' + flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Flight Year'].astype(str) + '_' + flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b900b9b-9303-4f4c-b065-eed83f24f8e7",
   "metadata": {},
   "source": [
    "Made 2x version, as not sure if the passengers' table is referring to the Operator or the Marketer.. we'll test both"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd32ce78-7440-4ac1-8e26-a50fe5ff981c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "flight_mkt = pd.DataFrame()\n",
    "unique_passengers = pd.DataFrame() \n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd40897-3241-40e6-9e7b-86ccf67904b0",
   "metadata": {},
   "source": [
    "Ok so the Flight Operator has more results, let's see the route that are not in the passengers table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3e3cda4-e34f-4ddd-803e-ce4aab29db73",
   "metadata": {},
   "source": [
    "print(flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711122f-fe74-489f-a43e-ba5c9f7bdb4d",
   "metadata": {},
   "source": [
    "This just made me notice something.. we don't have the data for 2020.. so we need to consolidate this information on a monthly thing. We'll need to reformat our route_ID to MM-carrier-origin-dest and then group the info of every year to either an average or a min/max where appropriate.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68358ceb-224e-410b-9ec3-dcbb7c337984",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Take 2 (dropped)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b24a13f7-90a4-4d0c-938d-6ea829d24c01",
   "metadata": {},
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a64ad44-d897-4cdc-91cc-2c41d6b61fa3",
   "metadata": {},
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "flight_mkt = pd.DataFrame()\n",
    "unique_passengers = pd.DataFrame() \n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b40e7-7346-4327-a21a-cdbe63308e13",
   "metadata": {},
   "source": [
    "Ok so the Flight Operator has more results, let's see the route that are not in the passengers table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7d58e77-d49e-40e0-a6e5-049ce68ae994",
   "metadata": {},
   "source": [
    "print(flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f55d2f-b537-4e6e-8a34-7f1ad50b891a",
   "metadata": {},
   "source": [
    "Ok, it looks like a fair amount is from our test... let's see..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0ced633-effd-416e-9741-be066b1dee32",
   "metadata": {},
   "source": [
    "count = flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])]\n",
    "count['Flight Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23d1e0-4dc2-46d0-a3b6-7ee38101c322",
   "metadata": {},
   "source": [
    "This is disappointing.. this probably means that we have new routes in our test.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda159c-6419-48e4-a2dc-fd204d9de8b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Take 3 - Month-depart-arrival (dropped)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7b1cd63-969a-4c13-b8f7-e89721cf3e4e",
   "metadata": {},
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_v3'] = flights_sample['Flight Month'].astype(str) + '-' +  flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "## We just need one in this case"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb2d53d6-a250-4b2e-b761-75b136d231f9",
   "metadata": {},
   "source": [
    "# Remove the carrier from the route ID column\n",
    "unique_passengers = pd.DataFrame()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "unique_passengers['routeid_month'] = unique_passengers['routeid'].str[:-11]\n",
    "unique_passengers['routeid_route'] = unique_passengers['routeid'].str[-8:]\n",
    "\n",
    "unique_passengers['routeid'] = unique_passengers['routeid_month'] + unique_passengers['routeid_route']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f796e-1695-4cc4-90f8-0767f80cb4ac",
   "metadata": {},
   "source": [
    "Let's see how this performs:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b22e85a-edcf-41ee-92d7-8d4efe60e023",
   "metadata": {},
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_v3'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flights\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Flight:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc00dba-cf2a-4c3b-8594-3e811f58c41e",
   "metadata": {},
   "source": [
    "This seems to perform better. Let's confirm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c00999c-ec86-4feb-abed-55cbd687839c",
   "metadata": {},
   "source": [
    "print(flights_sample[~flights_sample['routeId_v3'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_v3'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96f67e-2977-4c68-9470-02e1f5133a68",
   "metadata": {},
   "source": [
    "Still some missing from Jan 2020, damn!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b31cfef-d207-44f0-bda9-d1e06fd44975",
   "metadata": {},
   "source": [
    "count = flights_sample[~flights_sample['routeId_v3'].isin(unique_passengers['routeid'])]\n",
    "count['Flight Year'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c29bbc19-41bf-4753-a839-30b568c151cd",
   "metadata": {},
   "source": [
    "count['Flight Month'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c002e88-b3bf-411b-a41c-a6cd7071a232",
   "metadata": {},
   "source": [
    "flights_sample[(flights_sample['Flight Year'] == 2020) & (flights_sample['Flight Month'] == 1)].shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "909dfbe7-8869-4f08-bf89-76c859a07bfd",
   "metadata": {},
   "source": [
    "6741/660556*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68b6f1-3e96-477f-86c1-72e4aa92f60e",
   "metadata": {},
   "source": [
    "So we account for about 99% of the routes in January. It is better, but there is room for improvement. Also not a fan that we group all carriers together.. let's look at the other methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a924bb-d0b1-4d75-9ca7-a367bdb1313f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Take 4 - carrier-depart-arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26c083c-ed3e-4ed8-a9b4-9176953e27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d770867-6d0c-43e0-8164-67563f8d7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the carrier from the route ID column\n",
    "unique_passengers = pd.DataFrame()\n",
    "\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "unique_passengers['routeid'] = unique_passengers['routeid'].str[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ac700-fa6b-41fd-ab01-7a8f138c1b8c",
   "metadata": {},
   "source": [
    "Let's see how this performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2c9438-461b-4a84-ade0-84a80f921f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight Operator\n",
      "Total: 14632\n",
      "In passenger: 14555\n",
      "\n",
      "Flight Marketer\n",
      "Total: 9677\n",
      "In passenger: 8327\n",
      "\n",
      "Passengers Table\n",
      "Total: 612051\n",
      "In Marketer: 82861\n",
      "In Operator: 155357\n"
     ]
    }
   ],
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "flight_mkt = pd.DataFrame()\n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146bfde-0805-47af-8746-baa3a67327bd",
   "metadata": {},
   "source": [
    "This seems to perform better, and again Flight Operator is more commonly used. Let's confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019f05b6-cd39-4546-988d-f4b97966dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marketer - Unique Carrier Code</th>\n",
       "      <th>Operator - Unique Carrier Code</th>\n",
       "      <th>Tail Number</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Origin Airport (IATA Code)</th>\n",
       "      <th>Destination Airport (IATA Code)</th>\n",
       "      <th>Scheduled Departure Time (local time)</th>\n",
       "      <th>Scheduled Arrival Time (local time)</th>\n",
       "      <th>Scheduled Elapsed Time</th>\n",
       "      <th>Distance (miles)</th>\n",
       "      <th>Different Marketer &amp; Operator Carrier Code</th>\n",
       "      <th>Flight Weekday</th>\n",
       "      <th>Flight Day</th>\n",
       "      <th>Flight Month</th>\n",
       "      <th>Flight Year</th>\n",
       "      <th>Scheduled hour of departure</th>\n",
       "      <th>Scheduled hour of arrival</th>\n",
       "      <th>routeId_op</th>\n",
       "      <th>routeId_mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19386</th>\n",
       "      <td>UA</td>\n",
       "      <td>ZW</td>\n",
       "      <td>N446AW</td>\n",
       "      <td>3945</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CID</td>\n",
       "      <td>12:31</td>\n",
       "      <td>17:30</td>\n",
       "      <td>119</td>\n",
       "      <td>692</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>ZW-DEN-CID</td>\n",
       "      <td>UA-DEN-CID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19480</th>\n",
       "      <td>UA</td>\n",
       "      <td>ZW</td>\n",
       "      <td>N446AW</td>\n",
       "      <td>3843</td>\n",
       "      <td>CID</td>\n",
       "      <td>DEN</td>\n",
       "      <td>18:42</td>\n",
       "      <td>20:45</td>\n",
       "      <td>143</td>\n",
       "      <td>692</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>ZW-CID-DEN</td>\n",
       "      <td>UA-CID-DEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50861</th>\n",
       "      <td>G4</td>\n",
       "      <td>G4</td>\n",
       "      <td>279NV</td>\n",
       "      <td>6241</td>\n",
       "      <td>SAV</td>\n",
       "      <td>AVL</td>\n",
       "      <td>16:40</td>\n",
       "      <td>17:30</td>\n",
       "      <td>50</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>G4-SAV-AVL</td>\n",
       "      <td>G4-SAV-AVL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88414</th>\n",
       "      <td>DL</td>\n",
       "      <td>OO</td>\n",
       "      <td>N240SY</td>\n",
       "      <td>4010</td>\n",
       "      <td>RNO</td>\n",
       "      <td>LAS</td>\n",
       "      <td>16:40</td>\n",
       "      <td>18:35</td>\n",
       "      <td>75</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>OO-RNO-LAS</td>\n",
       "      <td>DL-RNO-LAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88561</th>\n",
       "      <td>DL</td>\n",
       "      <td>OO</td>\n",
       "      <td>N260SY</td>\n",
       "      <td>4159</td>\n",
       "      <td>RNO</td>\n",
       "      <td>LAS</td>\n",
       "      <td>03:10</td>\n",
       "      <td>05:05</td>\n",
       "      <td>75</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>OO-RNO-LAS</td>\n",
       "      <td>DL-RNO-LAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88741</th>\n",
       "      <td>DL</td>\n",
       "      <td>OO</td>\n",
       "      <td>N260SY</td>\n",
       "      <td>4734</td>\n",
       "      <td>LAS</td>\n",
       "      <td>MSP</td>\n",
       "      <td>06:25</td>\n",
       "      <td>14:45</td>\n",
       "      <td>180</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>OO-LAS-MSP</td>\n",
       "      <td>DL-LAS-MSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88744</th>\n",
       "      <td>DL</td>\n",
       "      <td>OO</td>\n",
       "      <td>N885AS</td>\n",
       "      <td>4743</td>\n",
       "      <td>ATL</td>\n",
       "      <td>MBS</td>\n",
       "      <td>09:20</td>\n",
       "      <td>13:10</td>\n",
       "      <td>150</td>\n",
       "      <td>683</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>OO-ATL-MBS</td>\n",
       "      <td>DL-ATL-MBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111022</th>\n",
       "      <td>AS</td>\n",
       "      <td>QX</td>\n",
       "      <td>N623QX</td>\n",
       "      <td>2954</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SAN</td>\n",
       "      <td>05:10</td>\n",
       "      <td>08:07</td>\n",
       "      <td>97</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>QX-SFO-SAN</td>\n",
       "      <td>AS-SFO-SAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112242</th>\n",
       "      <td>DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>N660DL</td>\n",
       "      <td>1703</td>\n",
       "      <td>TPA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>13:20</td>\n",
       "      <td>16:45</td>\n",
       "      <td>305</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>DL-TPA-LAS</td>\n",
       "      <td>DL-TPA-LAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113476</th>\n",
       "      <td>DL</td>\n",
       "      <td>DL</td>\n",
       "      <td>N916DU</td>\n",
       "      <td>2835</td>\n",
       "      <td>IND</td>\n",
       "      <td>LAS</td>\n",
       "      <td>04:40</td>\n",
       "      <td>06:43</td>\n",
       "      <td>263</td>\n",
       "      <td>1590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>DL-IND-LAS</td>\n",
       "      <td>DL-IND-LAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Marketer - Unique Carrier Code Operator - Unique Carrier Code  \\\n",
       "19386                              UA                             ZW   \n",
       "19480                              UA                             ZW   \n",
       "50861                              G4                             G4   \n",
       "88414                              DL                             OO   \n",
       "88561                              DL                             OO   \n",
       "88741                              DL                             OO   \n",
       "88744                              DL                             OO   \n",
       "111022                             AS                             QX   \n",
       "112242                             DL                             DL   \n",
       "113476                             DL                             DL   \n",
       "\n",
       "       Tail Number  Flight Number Origin Airport (IATA Code)  \\\n",
       "19386       N446AW           3945                        DEN   \n",
       "19480       N446AW           3843                        CID   \n",
       "50861        279NV           6241                        SAV   \n",
       "88414       N240SY           4010                        RNO   \n",
       "88561       N260SY           4159                        RNO   \n",
       "88741       N260SY           4734                        LAS   \n",
       "88744       N885AS           4743                        ATL   \n",
       "111022      N623QX           2954                        SFO   \n",
       "112242      N660DL           1703                        TPA   \n",
       "113476      N916DU           2835                        IND   \n",
       "\n",
       "       Destination Airport (IATA Code) Scheduled Departure Time (local time)  \\\n",
       "19386                              CID                                 12:31   \n",
       "19480                              DEN                                 18:42   \n",
       "50861                              AVL                                 16:40   \n",
       "88414                              LAS                                 16:40   \n",
       "88561                              LAS                                 03:10   \n",
       "88741                              MSP                                 06:25   \n",
       "88744                              MBS                                 09:20   \n",
       "111022                             SAN                                 05:10   \n",
       "112242                             LAS                                 13:20   \n",
       "113476                             LAS                                 04:40   \n",
       "\n",
       "       Scheduled Arrival Time (local time)  Scheduled Elapsed Time  \\\n",
       "19386                                17:30                     119   \n",
       "19480                                20:45                     143   \n",
       "50861                                17:30                      50   \n",
       "88414                                18:35                      75   \n",
       "88561                                05:05                      75   \n",
       "88741                                14:45                     180   \n",
       "88744                                13:10                     150   \n",
       "111022                               08:07                      97   \n",
       "112242                               16:45                     305   \n",
       "113476                               06:43                     263   \n",
       "\n",
       "        Distance (miles)  Different Marketer & Operator Carrier Code  \\\n",
       "19386                692                                           1   \n",
       "19480                692                                           1   \n",
       "50861                241                                           0   \n",
       "88414                345                                           1   \n",
       "88561                345                                           1   \n",
       "88741               1299                                           1   \n",
       "88744                683                                           1   \n",
       "111022               447                                           1   \n",
       "112242              1984                                           0   \n",
       "113476              1590                                           0   \n",
       "\n",
       "        Flight Weekday  Flight Day  Flight Month  Flight Year  \\\n",
       "19386                2           1             1         2020   \n",
       "19480                2           1             1         2020   \n",
       "50861                4           3             1         2020   \n",
       "88414                6           5             1         2020   \n",
       "88561                6           5             1         2020   \n",
       "88741                6           5             1         2020   \n",
       "88744                6           5             1         2020   \n",
       "111022               0           6             1         2020   \n",
       "112242               0           6             1         2020   \n",
       "113476               0           6             1         2020   \n",
       "\n",
       "        Scheduled hour of departure  Scheduled hour of arrival  routeId_op  \\\n",
       "19386                            12                         17  ZW-DEN-CID   \n",
       "19480                            18                         20  ZW-CID-DEN   \n",
       "50861                            16                         17  G4-SAV-AVL   \n",
       "88414                            16                         18  OO-RNO-LAS   \n",
       "88561                             3                          5  OO-RNO-LAS   \n",
       "88741                             6                         14  OO-LAS-MSP   \n",
       "88744                             9                         13  OO-ATL-MBS   \n",
       "111022                            5                          8  QX-SFO-SAN   \n",
       "112242                           13                         16  DL-TPA-LAS   \n",
       "113476                            4                          6  DL-IND-LAS   \n",
       "\n",
       "       routeId_mkt  \n",
       "19386   UA-DEN-CID  \n",
       "19480   UA-CID-DEN  \n",
       "50861   G4-SAV-AVL  \n",
       "88414   DL-RNO-LAS  \n",
       "88561   DL-RNO-LAS  \n",
       "88741   DL-LAS-MSP  \n",
       "88744   DL-ATL-MBS  \n",
       "111022  AS-SFO-SAN  \n",
       "112242  DL-TPA-LAS  \n",
       "113476  DL-IND-LAS  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93985bf-d821-49a1-8929-26affee5b805",
   "metadata": {},
   "source": [
    "Still some missing from Jan 2020, but we actually seem to have less this time. Let's confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8735598d-0484-4130-ae09-25eec9f450db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    993\n",
       "Name: Flight Year, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])]\n",
    "count['Flight Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b614433-b2bd-4a6d-a5d9-ebe2dff76008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    993\n",
       "Name: Flight Month, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count['Flight Month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b251b5-3f29-4ef5-9678-7fb3cf916422",
   "metadata": {},
   "source": [
    "it is better, but there is room for improvement, let's look at the other methods. Also not a fan that we group all carriers together.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2427452-502f-4c0d-97f3-b4abf586e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660556, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_sample[(flights_sample['Flight Year'] == 2020) & (flights_sample['Flight Month'] == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dceb8faa-8b9a-43af-bfaf-166022312cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15032790558256984"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "993/660556*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63635cb0-e8c0-4696-9955-7e7f2d3b8c0d",
   "metadata": {},
   "source": [
    "Okay, the proportion is almost negligible at this point We account for 99.85% of the routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5aeb47-6ca8-40fc-a871-a1385590e594",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Grouping the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "945a5fea-71e6-40e4-80d8-48749844bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 612051\n",
      "Unique values: 170839\n",
      "Duplicate values: 441212\n"
     ]
    }
   ],
   "source": [
    "#Lets see the duplicates\n",
    "\n",
    "passengers['routeid'] = passengers['routeid'].str[-10:]\n",
    "\n",
    "\n",
    "print(\"Total rows:\", passengers['routeid'].count())\n",
    "print(\"Unique values:\", passengers['routeid'].nunique())\n",
    "print(\"Duplicate values:\", passengers['routeid'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4536d6f3-555f-41e2-8ee7-a60c5dc00498",
   "metadata": {},
   "source": [
    "So each rows have about 5-6x values.. we'll group them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2413f83-ec80-47be-8458-b088b45c25d4",
   "metadata": {},
   "source": [
    "Before we group them, let's calculate the Freight ratio, the Mail Ratio as well as the amount of SeatOccupied, it will be more accurate than calculating once they are merged together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c4ab77-fe97-4e9d-8e09-415cbd7546db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 0s seem the be throwing off our calculations.. we'll switch them to NaNs\n",
    "passengers['availableseats'] = passengers['availableseats'].replace(0, np.nan)\n",
    "passengers['averagepassengers'] = passengers['averagepassengers'].replace(0, np.nan)\n",
    "passengers['averagepayload_lbs'] = passengers['averagepayload_lbs'].replace(0, np.nan)\n",
    "passengers['averagefreight_lbs'] = passengers['averagefreight_lbs'].replace(0, np.nan)\n",
    "passengers['averagemail_lbs'] = passengers['averagemail_lbs'].replace(0, np.nan)\n",
    "\n",
    "passengers['Proportion of freight to the payload'] = passengers['averagefreight_lbs'] / passengers['averagepayload_lbs']\n",
    "passengers['Proportion of mail to the payload'] = passengers['averagemail_lbs'] / passengers['averagepayload_lbs']\n",
    "passengers['Proportion of filled seats'] = passengers['averagepassengers'] / passengers['availableseats']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8eebd-fb09-4acc-b85c-76dd6c9ac270",
   "metadata": {},
   "source": [
    "We will group by routeid and avg the values for averagepayload_lbs, averagefreight_lbs, averagemail_lbs, availableseats, averagepassengers, distanceinterval_x500mi \n",
    "\n",
    "As well, aircraftgroup, aircrafttype, aircraftconfiguration, and serviceclass are all categorical variables, so we'll take the most common value for each group and return UNK if we don't have the info\n",
    "\n",
    "We're putting the grouping results into grouped_passengers, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9ed390e-76fc-4671-a44f-5b7f57a2dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switching the NANs to 'UNK'\n",
    "passengers['serviceclass'].fillna('UNK', inplace=True)\n",
    "passengers['aircraftgroup'].fillna('UNK', inplace=True)\n",
    "passengers['aircrafttype'].fillna('UNK', inplace=True)\n",
    "passengers['aircraftconfiguration'].fillna('UNK', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4c7b1-7a8a-4ae3-9320-3bbaa1fd63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_passengers = passengers.groupby(['routeid']).agg({'Proportion of freight to the payload': 'mean', 'Proportion of mail to the payload': 'mean', 'Proportion of filled seats': 'mean', 'averagepayload_lbs': 'mean', 'availableseats': 'mean', 'distanceinterval_x500mi': 'mean', 'aircraftgroup': lambda x: x.value_counts().index[1] if x.value_counts().index[0] == 'UNK' and len(x.value_counts()) > 1 else x.value_counts().index[0], 'aircrafttype': lambda x: x.value_counts().index[1] if x.value_counts().index[0] == 'UNK' and len(x.value_counts()) > 1 else x.value_counts().index[0], 'aircraftconfiguration': lambda x: x.value_counts().index[1] if x.value_counts().index[0] == 'UNK' and len(x.value_counts()) > 1 else x.value_counts().index[0], 'serviceclass': lambda x: x.value_counts().index[1] if x.value_counts().index[0] == 'UNK' and len(x.value_counts()) > 1 else x.value_counts().index[0]}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f74615-8db1-4ed9-ace7-934236cc4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(passengers.shape)\n",
    "print(grouped_passengers.shape)\n",
    "grouped_passengers.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88857c-55b1-4f3b-836c-15424580f961",
   "metadata": {},
   "source": [
    "And we're matching our unique values from above.. TRIPLE BAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce557b-199e-4e7b-b724-c61566d53390",
   "metadata": {},
   "source": [
    "# Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018bae6e-d55f-4096-b489-fb0b49c9e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_passengers.to_csv(\"../../data/processed/flights_enrichment_avgpayload_passengers.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
