{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d26012-92bc-45d2-851c-4ed2ff339f10",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c48004-dd6f-4fa5-872c-fa3481b3ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f57948-11aa-4cd0-a261-1999222d9409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flights_sample = pd.read_csv(\"../../data/processed/flights_sample.csv\", index_col=None)\n",
    "\n",
    "### Some Feature Engineering:\n",
    "\n",
    "# Change the column dtypes to the correct type for the date columns\n",
    "flights_sample['Scheduled Departure Time (local time)'] = pd.to_datetime(flights_sample['Scheduled Departure Time (local time)'])\n",
    "flights_sample['Actual Departure Time (local time)'] = pd.to_datetime(flights_sample['Actual Departure Time (local time)'])\n",
    "flights_sample['Wheels Off (local time)'] = pd.to_datetime(flights_sample['Wheels Off (local time)'])\n",
    "flights_sample['Wheels On (local time)'] = pd.to_datetime(flights_sample['Wheels On (local time)'])\n",
    "flights_sample['Scheduled Arrival Time (local time)'] = pd.to_datetime(flights_sample['Scheduled Arrival Time (local time)'])\n",
    "flights_sample['Actual Arrival Time (local time)'] = pd.to_datetime(flights_sample['Actual Arrival Time (local time)'])\n",
    "\n",
    "#Create a new column for the hour of the day for actual departure time and for wheels on time\n",
    "flights_sample['Actual Departure Hour'] = flights_sample['Actual Departure Time (local time)'].dt.hour  #I don't like that they are FLOATS.. would prefer int but having an error code because of NANs\n",
    "flights_sample['Wheels On Hour'] = flights_sample['Wheels On (local time)'].dt.hour #I don't like that they are FLOATS.. would prefer int but having an error code because of NANs\n",
    "\n",
    "# Create a new columns that calculates the difference between the departure delay and arrival delay\n",
    "flights_sample['Difference in Delay (Dep - Arr [minutes])'] = flights_sample['Departure Delay (minutes)'] - flights_sample['Arrival Delay (minutes)']\n",
    "\n",
    "#Create departure and arrival state column\n",
    "flights_sample['Departure State'] = flights_sample['Origin Airport (City, State)'].str[-2:]\n",
    "flights_sample['Arrival State'] = flights_sample['Destination Airport (City, State)'].str[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e373770-93f3-4c15-a21b-649e6e2023bf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199350 entries, 0 to 199349\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                      Non-Null Count   Dtype         \n",
      "---  ------                                      --------------   -----         \n",
      " 0   Flight Year                                 199350 non-null  int64         \n",
      " 1   Flight Month                                199350 non-null  int64         \n",
      " 2   Flight Day                                  199350 non-null  int64         \n",
      " 3   Flight Weekday                              199350 non-null  int64         \n",
      " 4   Marketer - Unique Carrier Code              199350 non-null  object        \n",
      " 5   Operator - Unique Carrier Code              199350 non-null  object        \n",
      " 6   Different Marketer & Operator Carrier Code  199350 non-null  int64         \n",
      " 7   Tail Number                                 199350 non-null  object        \n",
      " 8   Flight Number                               199350 non-null  int64         \n",
      " 9   Origin Airport (ID)                         199350 non-null  int64         \n",
      " 10  Origin Airport (IATA Code)                  199350 non-null  object        \n",
      " 11  Origin Airport (City, State)                199350 non-null  object        \n",
      " 12  Destination Airport (ID)                    199350 non-null  int64         \n",
      " 13  Destination Airport (IATA Code)             199350 non-null  object        \n",
      " 14  Destination Airport (City, State)           199350 non-null  object        \n",
      " 15  Departure Delay (minutes)                   199350 non-null  int64         \n",
      " 16  Arrival Delay (minutes)                     199350 non-null  int64         \n",
      " 17  Cancelled                                   199350 non-null  int64         \n",
      " 18  Cancellation Code                           2753 non-null    object        \n",
      " 19  Diverted                                    199350 non-null  int64         \n",
      " 20  Scheduled Departure Time (local time)       199350 non-null  datetime64[ns]\n",
      " 21  Actual Departure Time (local time)          196744 non-null  datetime64[ns]\n",
      " 22  Taxi Out (minutes)                          196542 non-null  object        \n",
      " 23  Wheels Off (local time)                     196542 non-null  datetime64[ns]\n",
      " 24  Wheels On (local time)                      196434 non-null  datetime64[ns]\n",
      " 25  Taxi In (minutes)                           196434 non-null  object        \n",
      " 26  Scheduled Arrival Time (local time)         199350 non-null  datetime64[ns]\n",
      " 27  Actual Arrival Time (local time)            196516 non-null  datetime64[ns]\n",
      " 28  Scheduled Elapsed Time                      199350 non-null  int64         \n",
      " 29  Actual Elapsed Time                         199350 non-null  int64         \n",
      " 30  Air Time                                    199350 non-null  int64         \n",
      " 31  Distance (miles)                            199350 non-null  int64         \n",
      " 32  Carrier Delay (minutes)                     199350 non-null  int64         \n",
      " 33  Weather Delay (minutes)                     199350 non-null  int64         \n",
      " 34  National Air System Delay (minutes)         199350 non-null  int64         \n",
      " 35  Security Delay (minutes)                    199350 non-null  int64         \n",
      " 36  Late Aircraft Delay (minutes)               199350 non-null  int64         \n",
      " 37  Actual Departure Hour                       196744 non-null  float64       \n",
      " 38  Wheels On Hour                              196434 non-null  float64       \n",
      " 39  Difference in Delay (Dep - Arr [minutes])   199350 non-null  int64         \n",
      " 40  Departure State                             199350 non-null  object        \n",
      " 41  Arrival State                               199350 non-null  object        \n",
      "dtypes: datetime64[ns](6), float64(2), int64(22), object(12)\n",
      "memory usage: 63.9+ MB\n"
     ]
    }
   ],
   "source": [
    "flights_sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e475dcb-d7f4-43ac-b705-3b0ea5928433",
   "metadata": {},
   "source": [
    "# Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afc082a3-8f02-4a54-bf99-6288a58a14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_airport = pd.read_csv(\"../../data/raw/unique_origin_airports.csv\", index_col=None)\n",
    "dest_airport = pd.read_csv(\"../../data/raw/unique_dest_airports.csv\", index_col=None)\n",
    "all_airports = np.concatenate((origin_airport, dest_airport))\n",
    "\n",
    "# Remove the duplicates\n",
    "all_airports = np.unique(all_airports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e267bb0-aaad-4c5f-8bcd-be48574610e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport_location = pd.read_csv(\"GlobalAirportDatabase.txt\", sep=\":\")\n",
    "\n",
    "# Add column headers to the airport_location df\n",
    "airport_location.columns = ['Airport ID', 'Airport Code', 'Airport Name', 'City', 'Country', 'Latitude Degrees', 'Latitude Minutes', 'Latitude Seconds', 'Latitude Direction', 'Longitude Degrees', 'Longitude Minutes', 'Longitude Seconds', 'Longitude Direction', 'Altitude', 'Latitude', 'Longitude']\n",
    "\n",
    "# Drop all the columns except the Airport Code, Name, City, Country, Latitude and Longitude\n",
    "airport_location = airport_location.drop(['Airport ID', 'Latitude Degrees', 'Latitude Minutes', 'Latitude Seconds', 'Latitude Direction', 'Longitude Degrees', 'Longitude Minutes', 'Longitude Seconds', 'Longitude Direction', 'Altitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18590af1-6c9e-4319-ae76-50b35acae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = airport_location['Airport Code'].isin(all_airports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "706dd840-19ca-4a70-9944-bc354f52ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy all records from airport_location that are in all_airports to a new df\n",
    "airport_latlong = airport_location[airport_location['Airport Code'].isin(all_airports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc95e81b-20e9-4124-b5e6-69de397e0981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_latlong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88411d9c-a4b6-44ce-894b-8f58e196b6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ABE', 'ABR', 'ACV', 'ALO', 'ALW', 'APN', 'ASE', 'ATW', 'ATY',\n",
       "       'AVL', 'AVP', 'AZA', 'AZO', 'BFF', 'BGM', 'BIL', 'BIS', 'BJI',\n",
       "       'BKG', 'BMI', 'BRD', 'BTM', 'BZN', 'CAK', 'CGI', 'CHO', 'CID',\n",
       "       'CIU', 'CKB', 'CMI', 'CMX', 'CNY', 'COD', 'CRW', 'CSG', 'CWA',\n",
       "       'DAB', 'DBQ', 'DIK', 'DVL', 'EAR', 'EAT', 'EAU', 'ECP', 'EGE',\n",
       "       'EKO', 'ELM', 'ERI', 'ESC', 'EUG', 'EVV', 'FAR', 'FAY', 'FCA',\n",
       "       'FLG', 'FNT', 'FSD', 'FWA', 'GCC', 'GJT', 'GPT', 'GRI', 'GSO',\n",
       "       'GSP', 'GST', 'GTR', 'GUC', 'HDN', 'HGR', 'HHH', 'HSV', 'HTS',\n",
       "       'HVN', 'HYA', 'HYS', 'IDA', 'IFP', 'IMT', 'ITH', 'JAC', 'JLN',\n",
       "       'JMS', 'LAR', 'LAW', 'LBE', 'LBF', 'LBL', 'LEX', 'LSE', 'LWB',\n",
       "       'LWS', 'LYH', 'MBS', 'MEI', 'MFR', 'MGM', 'MHK', 'MHT', 'MKG',\n",
       "       'MLI', 'MMH', 'MRY', 'MSO', 'MTJ', 'MVY', 'OAJ', 'OGD', 'ORH',\n",
       "       'OTH', 'OWB', 'PAH', 'PGD', 'PGV', 'PIA', 'PIB', 'PIH', 'PIR',\n",
       "       'PLN', 'PSC', 'PSG', 'PSM', 'PUW', 'PVU', 'RAP', 'RDD', 'RDM',\n",
       "       'RFD', 'RHI', 'RKS', 'ROA', 'RST', 'SBA', 'SBN', 'SBP', 'SCE',\n",
       "       'SDF', 'SGF', 'SGU', 'SHD', 'SLN', 'SMX', 'SPI', 'SRQ', 'STC',\n",
       "       'STS', 'SUN', 'SWO', 'TOL', 'TRI', 'TVC', 'TWF', 'UIN', 'USA',\n",
       "       'VEL', 'VLD', 'WRG', 'WYS', 'XNA', 'XWA', 'YKM'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_airports = np.setdiff1d(all_airports, airport_latlong['Airport Code'].values)\n",
    "missing_airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ea7b780-96ec-434e-a614-be27130282ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Airport Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAE</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAG</td>\n",
       "      <td>MADANG</td>\n",
       "      <td>MADANG</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>-5.207</td>\n",
       "      <td>145.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HGU</td>\n",
       "      <td>MOUNT HAGEN</td>\n",
       "      <td>MOUNT HAGEN</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>-5.826</td>\n",
       "      <td>144.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAE</td>\n",
       "      <td>NADZAB</td>\n",
       "      <td>NADZAB</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>-6.570</td>\n",
       "      <td>146.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POM</td>\n",
       "      <td>PORT MORESBY JACKSONS INTERNATIONAL</td>\n",
       "      <td>PORT MORESBY</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>-9.443</td>\n",
       "      <td>147.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHENYANG</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9295</th>\n",
       "      <td>DLC</td>\n",
       "      <td>ZHOUSHUIZI</td>\n",
       "      <td>DALIAN</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>38.966</td>\n",
       "      <td>121.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XIANCHENG</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YICHUN</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YANJI</td>\n",
       "      <td>YANJI</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>42.882</td>\n",
       "      <td>129.448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9082 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Airport Code                         Airport Name          City  \\\n",
       "0             LAE                                  NaN           LAE   \n",
       "1             MAG                               MADANG        MADANG   \n",
       "2             HGU                          MOUNT HAGEN   MOUNT HAGEN   \n",
       "3             LAE                               NADZAB        NADZAB   \n",
       "4             POM  PORT MORESBY JACKSONS INTERNATIONAL  PORT MORESBY   \n",
       "...           ...                                  ...           ...   \n",
       "9294          NaN                                  NaN      SHENYANG   \n",
       "9295          DLC                           ZHOUSHUIZI        DALIAN   \n",
       "9296          NaN                                  NaN     XIANCHENG   \n",
       "9297          NaN                                  NaN        YICHUN   \n",
       "9298          NaN                                YANJI         YANJI   \n",
       "\n",
       "               Country  Latitude  Longitude  \n",
       "0     PAPUA NEW GUINEA     0.000      0.000  \n",
       "1     PAPUA NEW GUINEA    -5.207    145.789  \n",
       "2     PAPUA NEW GUINEA    -5.826    144.296  \n",
       "3     PAPUA NEW GUINEA    -6.570    146.726  \n",
       "4     PAPUA NEW GUINEA    -9.443    147.220  \n",
       "...                ...       ...        ...  \n",
       "9294             CHINA     0.000      0.000  \n",
       "9295             CHINA    38.966    121.538  \n",
       "9296             CHINA     0.000      0.000  \n",
       "9297             CHINA     0.000      0.000  \n",
       "9298             CHINA    42.882    129.448  \n",
       "\n",
       "[9082 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c13fce74-5848-42e7-8c23-90cd22016bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2018 = pd.read_csv('2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac2f7bc4-71c3-4b5a-a58a-e6d940b9c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36333281 entries, 0 to 36333280\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   AE000041196  object \n",
      " 1   20180101     int64  \n",
      " 2   TMAX         object \n",
      " 3   259          int64  \n",
      " 4   Unnamed: 4   object \n",
      " 5   Unnamed: 5   object \n",
      " 6   S            object \n",
      " 7   Unnamed: 7   float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "raw2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b42c8b0c-ace9-4a09-9091-bd13244598c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aberdeen, SD', 'Abilene, TX', 'Adak Island, AK', 'Aguadilla, PR',\n",
       "       'Akron, OH', 'Albany, GA', 'Albany, NY', 'Albuquerque, NM',\n",
       "       'Alexandria, LA', 'Allentown/Bethlehem/Easton, PA', 'Alpena, MI',\n",
       "       'Amarillo, TX', 'Anchorage, AK', 'Appleton, WI',\n",
       "       'Arcata/Eureka, CA', 'Asheville, NC', 'Ashland, WV', 'Aspen, CO',\n",
       "       'Atlanta, GA', 'Atlantic City, NJ', 'Augusta, GA', 'Austin, TX',\n",
       "       'Bakersfield, CA', 'Baltimore, MD', 'Bangor, ME', 'Barrow, AK',\n",
       "       'Baton Rouge, LA', 'Beaumont/Port Arthur, TX', 'Belleville, IL',\n",
       "       'Bellingham, WA', 'Bemidji, MN', 'Bend/Redmond, OR', 'Bethel, AK',\n",
       "       'Billings, MT', 'Binghamton, NY', 'Birmingham, AL',\n",
       "       'Bismarck/Mandan, ND', 'Bloomington/Normal, IL', 'Boise, ID',\n",
       "       'Boston, MA', 'Bozeman, MT', 'Brainerd, MN', 'Branson, MO',\n",
       "       'Bristol/Johnson City/Kingsport, TN', 'Brownsville, TX',\n",
       "       'Brunswick, GA', 'Buffalo, NY', 'Burbank, CA', 'Burlington, VT',\n",
       "       'Butte, MT', 'Cape Girardeau, MO', 'Casper, WY', 'Cedar City, UT',\n",
       "       'Cedar Rapids/Iowa City, IA', 'Champaign/Urbana, IL',\n",
       "       'Charleston, SC', 'Charleston/Dunbar, WV', 'Charlotte Amalie, VI',\n",
       "       'Charlotte, NC', 'Charlottesville, VA', 'Chattanooga, TN',\n",
       "       'Cheyenne, WY', 'Chicago, IL', 'Christiansted, VI',\n",
       "       'Cincinnati, OH', 'Clarksburg/Fairmont, WV', 'Cleveland, OH',\n",
       "       'Cody, WY', 'College Station/Bryan, TX', 'Colorado Springs, CO',\n",
       "       'Columbia, MO', 'Columbia, SC', 'Columbus, GA', 'Columbus, MS',\n",
       "       'Columbus, OH', 'Concord, NC', 'Cordova, AK', 'Corpus Christi, TX',\n",
       "       'Dallas, TX', 'Dallas/Fort Worth, TX', 'Dayton, OH',\n",
       "       'Daytona Beach, FL', 'Deadhorse, AK', 'Del Rio, TX', 'Denver, CO',\n",
       "       'Des Moines, IA', 'Detroit, MI', 'Devils Lake, ND',\n",
       "       'Dickinson, ND', 'Dillingham, AK', 'Dothan, AL', 'Dubuque, IA',\n",
       "       'Duluth, MN', 'Durango, CO', 'Eagle, CO', 'Eau Claire, WI',\n",
       "       'El Paso, TX', 'Elko, NV', 'Elmira/Corning, NY', 'Erie, PA',\n",
       "       'Escanaba, MI', 'Eugene, OR', 'Evansville, IN', 'Everett, WA',\n",
       "       'Fairbanks, AK', 'Fargo, ND', 'Fayetteville, AR',\n",
       "       'Fayetteville, NC', 'Flagstaff, AZ', 'Flint, MI', 'Florence, SC',\n",
       "       'Fort Lauderdale, FL', 'Fort Myers, FL', 'Fort Smith, AR',\n",
       "       'Fort Wayne, IN', 'Fresno, CA', 'Gainesville, FL',\n",
       "       'Garden City, KS', 'Gillette, WY', 'Grand Forks, ND',\n",
       "       'Grand Island, NE', 'Grand Junction, CO', 'Grand Rapids, MI',\n",
       "       'Great Falls, MT', 'Green Bay, WI', 'Greensboro/High Point, NC',\n",
       "       'Greenville, NC', 'Greer, SC', 'Guam, TT', 'Gulfport/Biloxi, MS',\n",
       "       'Gunnison, CO', 'Gustavus, AK', 'Hagerstown, MD',\n",
       "       'Hancock/Houghton, MI', 'Harlingen/San Benito, TX',\n",
       "       'Harrisburg, PA', 'Hartford, CT', 'Hattiesburg/Laurel, MS',\n",
       "       'Hayden, CO', 'Hays, KS', 'Helena, MT', 'Hibbing, MN', 'Hilo, HI',\n",
       "       'Hilton Head, SC', 'Hobbs, NM', 'Honolulu, HI', 'Hoolehua, HI',\n",
       "       'Houston, TX', 'Huntsville, AL', 'Hyannis, MA', 'Idaho Falls, ID',\n",
       "       'Indianapolis, IN', 'International Falls, MN',\n",
       "       'Iron Mountain/Kingsfd, MI', 'Islip, NY', 'Ithaca/Cortland, NY',\n",
       "       'Jackson, WY', 'Jackson/Vicksburg, MS', 'Jacksonville, FL',\n",
       "       'Jacksonville/Camp Lejeune, NC', 'Jamestown, ND', 'Joplin, MO',\n",
       "       'Juneau, AK', 'Kahului, HI', 'Kalamazoo, MI', 'Kalispell, MT',\n",
       "       'Kansas City, MO', 'Kapalua, HI', 'Kearney, NE', 'Ketchikan, AK',\n",
       "       'Key West, FL', 'Killeen, TX', 'Knoxville, TN', 'Kodiak, AK',\n",
       "       'Kona, HI', 'Kotzebue, AK', 'La Crosse, WI', 'Lafayette, LA',\n",
       "       'Lake Charles, LA', 'Lanai, HI', 'Lansing, MI', 'Laramie, WY',\n",
       "       'Laredo, TX', 'Las Vegas, NV', 'Latrobe, PA',\n",
       "       'Lawton/Fort Sill, OK', 'Lewisburg, WV', 'Lewiston, ID',\n",
       "       'Lexington, KY', 'Liberal, KS', 'Lihue, HI', 'Lincoln, NE',\n",
       "       'Little Rock, AR', 'Long Beach, CA', 'Longview, TX',\n",
       "       'Los Angeles, CA', 'Louisville, KY', 'Lubbock, TX',\n",
       "       'Lynchburg, VA', 'Madison, WI', 'Mammoth Lakes, CA',\n",
       "       'Manchester, NH', 'Manhattan/Ft. Riley, KS', 'Marquette, MI',\n",
       "       \"Martha's Vineyard, MA\", 'Medford, OR', 'Melbourne, FL',\n",
       "       'Memphis, TN', 'Meridian, MS', 'Miami, FL', 'Midland/Odessa, TX',\n",
       "       'Milwaukee, WI', 'Minneapolis, MN', 'Minot, ND',\n",
       "       'Mission/McAllen/Edinburg, TX', 'Missoula, MT', 'Moab, UT',\n",
       "       'Mobile, AL', 'Moline, IL', 'Monroe, LA', 'Monterey, CA',\n",
       "       'Montgomery, AL', 'Montrose/Delta, CO', 'Mosinee, WI',\n",
       "       'Muskegon, MI', 'Myrtle Beach, SC', 'Nantucket, MA',\n",
       "       'Nashville, TN', 'New Bern/Morehead/Beaufort, NC', 'New Haven, CT',\n",
       "       'New Orleans, LA', 'New York, NY', 'Newark, NJ',\n",
       "       'Newburgh/Poughkeepsie, NY', 'Newport News/Williamsburg, VA',\n",
       "       'Niagara Falls, NY', 'Nome, AK', 'Norfolk, VA',\n",
       "       'North Bend/Coos Bay, OR', 'North Platte, NE', 'Oakland, CA',\n",
       "       'Ogden, UT', 'Ogdensburg, NY', 'Oklahoma City, OK', 'Omaha, NE',\n",
       "       'Ontario, CA', 'Orlando, FL', 'Owensboro, KY', 'Paducah, KY',\n",
       "       'Pago Pago, TT', 'Palm Springs, CA', 'Panama City, FL',\n",
       "       'Pasco/Kennewick/Richland, WA', 'Pellston, MI', 'Pensacola, FL',\n",
       "       'Peoria, IL', 'Petersburg, AK', 'Philadelphia, PA', 'Phoenix, AZ',\n",
       "       'Pierre, SD', 'Pittsburgh, PA', 'Plattsburgh, NY', 'Pocatello, ID',\n",
       "       'Ponce, PR', 'Portland, ME', 'Portland, OR', 'Portsmouth, NH',\n",
       "       'Prescott, AZ', 'Presque Isle/Houlton, ME', 'Providence, RI',\n",
       "       'Provo, UT', 'Pueblo, CO', 'Pullman, WA', 'Punta Gorda, FL',\n",
       "       'Quincy, IL', 'Raleigh/Durham, NC', 'Rapid City, SD',\n",
       "       'Redding, CA', 'Reno, NV', 'Rhinelander, WI', 'Richmond, VA',\n",
       "       'Roanoke, VA', 'Rochester, MN', 'Rochester, NY',\n",
       "       'Rock Springs, WY', 'Rockford, IL', 'Roswell, NM', 'Rota, TT',\n",
       "       'Sacramento, CA', 'Saginaw/Bay City/Midland, MI', 'Saipan, TT',\n",
       "       'Salina, KS', 'Salisbury, MD', 'Salt Lake City, UT',\n",
       "       'San Angelo, TX', 'San Antonio, TX', 'San Diego, CA',\n",
       "       'San Francisco, CA', 'San Jose, CA', 'San Juan, PR',\n",
       "       'San Luis Obispo, CA', 'Sanford, FL', 'Santa Ana, CA',\n",
       "       'Santa Barbara, CA', 'Santa Fe, NM', 'Santa Maria, CA',\n",
       "       'Santa Rosa, CA', 'Sarasota/Bradenton, FL', 'Sault Ste. Marie, MI',\n",
       "       'Savannah, GA', 'Scottsbluff, NE', 'Scranton/Wilkes-Barre, PA',\n",
       "       'Seattle, WA', 'Shreveport, LA', 'Sioux City, IA',\n",
       "       'Sioux Falls, SD', 'Sitka, AK', 'South Bend, IN', 'Spokane, WA',\n",
       "       'Springfield, IL', 'Springfield, MO', 'St. Cloud, MN',\n",
       "       'St. George, UT', 'St. Louis, MO', 'St. Petersburg, FL',\n",
       "       'State College, PA', 'Staunton, VA', 'Stillwater, OK',\n",
       "       'Stockton, CA', 'Sun Valley/Hailey/Ketchum, ID', 'Syracuse, NY',\n",
       "       'Tallahassee, FL', 'Tampa, FL', 'Texarkana, AR', 'Toledo, OH',\n",
       "       'Traverse City, MI', 'Trenton, NJ', 'Tucson, AZ', 'Tulsa, OK',\n",
       "       'Twin Falls, ID', 'Tyler, TX', 'Unalaska, AK', 'Valdosta, GA',\n",
       "       'Valparaiso, FL', 'Vernal, UT', 'Waco, TX', 'Walla Walla, WA',\n",
       "       'Washington, DC', 'Waterloo, IA', 'Watertown, NY', 'Watertown, SD',\n",
       "       'Wenatchee, WA', 'West Palm Beach/Palm Beach, FL',\n",
       "       'West Yellowstone, MT', 'White Plains, NY', 'Wichita Falls, TX',\n",
       "       'Wichita, KS', 'Williamsport, PA', 'Williston, ND',\n",
       "       'Wilmington, NC', 'Worcester, MA', 'Wrangell, AK', 'Yakima, WA',\n",
       "       'Yakutat, AK', 'Youngstown/Warren, OH', 'Yuma, AZ'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that contain the cities of the airports\n",
    "departure_airport_cities = flights_sample['Origin Airport (City, State)'].unique()\n",
    "arrival_airport_cities = flights_sample['Destination Airport (City, State)'].unique()\n",
    "airport_cities = np.concatenate((departure_airport_cities, arrival_airport_cities))\n",
    "# remove the duplicates\n",
    "airport_cities = np.unique(airport_cities)\n",
    "\n",
    "airport_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c3d1c1c-60f2-4a8f-b1d8-07c591958a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LAS', 'SYR', 'ELP', 'DEN', 'ATL', 'TRI', 'SMF', 'EWR', 'CLT',\n",
       "       'EUG', 'AUS', 'DCA', 'GRR', 'STL', 'FAI', 'SEA', 'SJC', 'ORD',\n",
       "       'BWI', 'LFT', 'HOU', 'BOS', 'LAX', 'SFB', 'DTW', 'JLN', 'JFK',\n",
       "       'PHL', 'MEM', 'DFW', 'PHX', 'IAD', 'SDF', 'KOA', 'MCO', 'BTV',\n",
       "       'ORF', 'ABQ', 'MKE', 'LGA', 'FLL', 'MDT', 'MIA', 'CLE', 'PWM',\n",
       "       'SNA', 'HNL', 'HSV', 'IND', 'IAH', 'RNO', 'SLC', 'ROC', 'RSW',\n",
       "       'SAT', 'CMI', 'MSP', 'LRD', 'PDX', 'SFO', 'RIC', 'MSY', 'MDW',\n",
       "       'OMA', 'RDU', 'EWN', 'ECP', 'ACY', 'CAK', 'CMH', 'OAK', 'DRO',\n",
       "       'CVG', 'GEG', 'LIT', 'BNA', 'CHA', 'BUF', 'ANC', 'JAX', 'COS',\n",
       "       'SAN', 'HPN', 'XNA', 'ONT', 'SRQ', 'AGS', 'ROA', 'SAV', 'RDD',\n",
       "       'BTR', 'TPA', 'PVD', 'PSP', 'MYR', 'BDL', 'MSN', 'BZN', 'JAN',\n",
       "       'SAF', 'LWS', 'GRB', 'CAE', 'DAL', 'PBG', 'BUR', 'VPS', 'CHS',\n",
       "       'PAH', 'FSD', 'LIH', 'ALW', 'OKC', 'OGG', 'GSP', 'COU', 'BOI',\n",
       "       'SPS', 'BHM', 'GSO', 'MFE', 'ALB', 'ERI', 'IPT', 'LGB', 'GFK',\n",
       "       'MSO', 'MGM', 'BET', 'ITO', 'GTF', 'MCI', 'VLD', 'ICT', 'TYS',\n",
       "       'ASE', 'BLI', 'SCC', 'BGR', 'SGF', 'SJU', 'BFL', 'BRO', 'LBE',\n",
       "       'EVV', 'AZO', 'MFR', 'GPT', 'AVL', 'JAC', 'MTJ', 'ROW', 'PIT',\n",
       "       'BPT', 'TVC', 'ATW', 'PNS', 'DSM', 'DAY', 'AVP', 'PIB', 'ABE',\n",
       "       'FCA', 'ELM', 'PHF', 'FWA', 'CRP', 'BIL', 'PBI', 'CSG', 'LNK',\n",
       "       'MHT', 'AEX', 'HRL', 'MLI', 'MRY', 'PAE', 'GJT', 'JNU', 'TUL',\n",
       "       'RAP', 'FAR', 'MLB', 'STT', 'SJT', 'TLH', 'GCC', 'ABR', 'SUX',\n",
       "       'ILM', 'MOB', 'MBS', 'CID', 'MLU', 'BQN', 'LBB', 'FLO', 'TUS',\n",
       "       'LEX', 'CRW', 'IDA', 'PSG', 'ALO', 'SBA', 'HLN', 'TTN', 'ACK',\n",
       "       'CHO', 'MAF', 'TWF', 'ACV', 'TOL', 'SHD', 'ACT', 'SGU', 'PSC',\n",
       "       'PIE', 'COD', 'SHV', 'PLN', 'MHK', 'YUM', 'ITH', 'MEI', 'IAG',\n",
       "       'EKO', 'SBN', 'PGD', 'FAY', 'FAT', 'HIB', 'LAN', 'ISN', 'CMX',\n",
       "       'DIK', 'ABI', 'FNT', 'TYR', 'RDM', 'DVL', 'AMA', 'PQI', 'STS',\n",
       "       'JHM', 'SWF', 'KTN', 'AZA', 'ABY', 'SUN', 'RKS', 'SIT', 'LYH',\n",
       "       'GGG', 'PUB', 'EAU', 'LSE', 'MKK', 'CIU', 'GNV', 'GUM', 'SBY',\n",
       "       'EYW', 'BIS', 'RST', 'USA', 'YKM', 'DAB', 'BMI', 'OTH', 'PSM',\n",
       "       'SCK', 'CNY', 'YAK', 'EAT', 'GRK', 'ISP', 'RHI', 'DLH', 'GRI',\n",
       "       'SPN', 'HDN', 'CLL', 'BLV', 'SLN', 'CPR', 'CWA', 'SBP', 'HHH',\n",
       "       'HYS', 'SCE', 'PIA', 'BRD', 'HTS', 'FLG', 'MOT', 'BGM', 'INL',\n",
       "       'GTR', 'UIN', 'LAW', 'EGE', 'LNY', 'STX', 'DBQ', 'BQK', 'EAR',\n",
       "       'SPI', 'XWA', 'OTZ', 'ADQ', 'RFD', 'GUC', 'OME', 'BRW', 'IMT',\n",
       "       'SWO', 'OGS', 'LBF', 'OAJ', 'BFF', 'CKB', 'ORH', 'JMS', 'TXK',\n",
       "       'PUW', 'MMH', 'MVY', 'LCK', 'VEL', 'LWB', 'DRT', 'PRC', 'CGI',\n",
       "       'ROP', 'MQT', 'DHN', 'GCK', 'WRG', 'HOB', 'FSM', 'HVN', 'PIH',\n",
       "       'PVU', 'LCH', 'LAR', 'PGV', 'PSE', 'ESC', 'CDC', 'ART', 'BKG',\n",
       "       'MKG', 'CDV', 'LBL', 'HGR', 'DUT', 'OWB', 'OGD', 'CYS', 'BJI',\n",
       "       'APN', 'ATY', 'WYS', 'GST', 'SMX', 'BTM', 'PPG', 'PIR', 'DLG',\n",
       "       'HYA', 'STC', 'ADK', 'YNG', 'BFM', 'ORD', 'CLT', 'DAL', 'CHS',\n",
       "       'TPA', 'LAS', 'JAX', 'BOS', 'DEN', 'IAD', 'MCI', 'ATL', 'STL',\n",
       "       'SEA', 'PHL', 'HNL', 'DCA', 'BDL', 'DFW', 'PHX', 'LAX', 'MFE',\n",
       "       'MCO', 'PSC', 'ANC', 'RDU', 'ORF', 'TUS', 'FLL', 'MSP', 'CHA',\n",
       "       'SLC', 'TXK', 'CLE', 'CAE', 'BWI', 'PRC', 'MHT', 'EWR', 'MDT',\n",
       "       'ATW', 'SBY', 'TYS', 'MIA', 'DTW', 'ICT', 'LGA', 'OAK', 'MFR',\n",
       "       'IND', 'PDX', 'SDF', 'SGU', 'JFK', 'BUF', 'SFO', 'SAT', 'BUR',\n",
       "       'GRB', 'BNA', 'ONT', 'RSW', 'CVG', 'MDW', 'AUS', 'GSP', 'SNA',\n",
       "       'CMH', 'GEG', 'PBI', 'SCC', 'MLI', 'ABQ', 'SJC', 'CLL', 'SCE',\n",
       "       'IAH', 'STS', 'PHF', 'HDN', 'EYW', 'DSM', 'PIT', 'SMF', 'HSV',\n",
       "       'SPS', 'RDM', 'AVL', 'LGB', 'IPT', 'BOI', 'DAY', 'SAN', 'ELP',\n",
       "       'LAN', 'ILM', 'SAV', 'BLV', 'MSO', 'OKC', 'RNO', 'LIH', 'GRK',\n",
       "       'RST', 'GSO', 'FAT', 'MSY', 'BTV', 'TUL', 'BHM', 'SYR', 'LEX',\n",
       "       'CRP', 'PSP', 'MKE', 'AZA', 'FAR', 'GPT', 'CAK', 'HOU', 'SBP',\n",
       "       'GTF', 'COD', 'RIC', 'LYH', 'XNA', 'PVD', 'LRD', 'OMA', 'ROC',\n",
       "       'TRI', 'LBB', 'LFT', 'ACY', 'MSN', 'LNY', 'ITH', 'MYR', 'SGF',\n",
       "       'MEM', 'ROA', 'SBN', 'GNV', 'MLB', 'ERI', 'SRQ', 'PUB', 'LNK',\n",
       "       'CWA', 'ACK', 'AMA', 'SJU', 'OTZ', 'FWA', 'SAF', 'ELM', 'OGG',\n",
       "       'PWM', 'FCA', 'CDV', 'FSD', 'APN', 'TOL', 'TLH', 'BTR', 'ABE',\n",
       "       'PAE', 'EVV', 'FAI', 'GRR', 'FLO', 'BIL', 'DRO', 'JHM', 'DAB',\n",
       "       'DIK', 'CRW', 'BGR', 'CHO', 'LIT', 'MAF', 'VPS', 'GJT', 'HPN',\n",
       "       'BZN', 'SBA', 'ALB', 'BLI', 'EUG', 'PIA', 'KOA', 'AGS', 'DBQ',\n",
       "       'HLN', 'GCC', 'JNU', 'FLG', 'WRG', 'ECP', 'SHV', 'COS', 'JAC',\n",
       "       'MLU', 'OAJ', 'CMI', 'PIE', 'MOB', 'ADQ', 'BRO', 'BQN', 'USA',\n",
       "       'ASE', 'IDA', 'IAG', 'AVP', 'GCK', 'LAR', 'MTJ', 'ISP', 'PIB',\n",
       "       'ITO', 'LSE', 'ABY', 'LCH', 'PNS', 'ABR', 'PGV', 'SFB', 'CID',\n",
       "       'TYR', 'JAN', 'HRL', 'STT', 'LCK', 'STX', 'MBS', 'SUN', 'AZO',\n",
       "       'HIB', 'TVC', 'PBG', 'TTN', 'BGM', 'MHK', 'MMH', 'HTS', 'BFL',\n",
       "       'RFD', 'BPT', 'FNT', 'MOT', 'BMI', 'BET', 'JLN', 'BTM', 'UIN',\n",
       "       'SPN', 'AEX', 'COU', 'FAY', 'SIT', 'EKO', 'PIH', 'ACV', 'LBF',\n",
       "       'DLH', 'ABI', 'PGD', 'ALO', 'GUM', 'SJT', 'CGI', 'ORH', 'INL',\n",
       "       'RAP', 'BIS', 'MEI', 'EAT', 'HYS', 'ALW', 'OGS', 'SLN', 'LBE',\n",
       "       'SWF', 'SUX', 'ART', 'YKM', 'LWB', 'MGM', 'MRY', 'GFK', 'PAH',\n",
       "       'CPR', 'FSM', 'CNY', 'YUM', 'CMX', 'OTH', 'EAR', 'JMS', 'LBL',\n",
       "       'OME', 'DHN', 'WYS', 'SPI', 'KTN', 'HHH', 'ESC', 'HGR', 'ACT',\n",
       "       'PUW', 'BQK', 'LAW', 'GGG', 'XWA', 'GUC', 'CKB', 'PLN', 'EWN',\n",
       "       'CDC', 'LWS', 'DVL', 'VEL', 'RDD', 'BKG', 'PSE', 'EGE', 'GTR',\n",
       "       'MKK', 'GRI', 'ISN', 'PSG', 'SWO', 'CIU', 'DUT', 'ROW', 'PIR',\n",
       "       'BRW', 'TWF', 'BRD', 'MVY', 'PQI', 'VLD', 'SCK', 'IMT', 'OGD',\n",
       "       'RKS', 'MQT', 'PVU', 'SMX', 'EAU', 'BFF', 'PSM', 'RHI', 'HVN',\n",
       "       'HOB', 'CSG', 'OWB', 'SHD', 'DRT', 'CYS', 'MKG', 'YAK', 'ATY',\n",
       "       'BJI', 'HYA', 'BFM', 'PPG', 'ROP', 'STC', 'DLG'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all Airport codes\n",
    "departure_airports = flights_sample['Origin Airport (IATA Code)'].unique()\n",
    "arrival_airports = flights_sample['Destination Airport (IATA Code)'].unique()\n",
    "airport_codes = np.concatenate((departure_airports, arrival_airports))\n",
    "#airport_codes.size\n",
    "airport_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80e8be-53e3-4a35-b795-a753c4e14d84",
   "metadata": {},
   "source": [
    "Okay, so we need to look at 745x different airports we would need to get the weather from, on a daily basis for 2 years and 7x days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d4370f0-ffcb-46ae-ba2d-1ad30fd379d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(745 * ((2 * 12) + 1)) / 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83872e2a-87ef-4d81-87d1-0c9734d85a75",
   "metadata": {},
   "source": [
    "If we're going by day. that's a total of ~550,000 API calls.. and this is just for the sample.. we could have more than 745 airports to look at.. \n",
    "\n",
    "World Weather API is only allowing 500 request a day, so if we can pull 2x yars per API call, we should be able to pull all airports in 2x days\n",
    "- The local History API can only pull a month at a time.. that's a bummer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8e7f1-e1bb-4c74-b39a-37346d6424f8",
   "metadata": {},
   "source": [
    "https://home.openweathermap.org/history_bulks/new\n",
    "\n",
    "Allows to do complete history pulls for 10USD a pull.. wow.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c9abe-0b42-4387-9130-f9699bda76e1",
   "metadata": {},
   "source": [
    "https://rapidapi.com/iddogino/api/global-weather-history/pricing\n",
    "\n",
    "This guy allows 10,000 pull a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "564be935-19c8-4e84-b1a3-571968f57579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#World Weather API can pull a month at a time.. 500x calls a day.. \n",
    "500 / 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60912fd2-6dd2-4a62-adcc-3ad73ffffdbb",
   "metadata": {},
   "source": [
    "If we can break down in roughly 20 values we could be good.. what about per states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f01c4afe-bf5c-43a8-a02d-f2bdb99ac02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consolidate the States into a single list\n",
    "departure_states = flights_sample['Departure State'].unique()\n",
    "arrival_states = flights_sample['Arrival State'].unique()\n",
    "states = np.concatenate((departure_states, arrival_states))\n",
    "# remove the duplicates\n",
    "states = np.unique(states)\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c437e6-18eb-4b12-a92f-d37f99452dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05388ab-3d72-4501-8d07-3bd2d6d27c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc8ab9-2b7f-4010-9844-6a1dec38e98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5828403d-1fe8-4f5c-b2fa-6e9017aca117",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Found this article that is scrapping Weather Underground Data using BeautifulSoup.\n",
    "https://flowingdata.com/2007/07/09/grabbing-weather-underground-data-with-beautifulsoup/\n",
    "\n",
    "Will use it as a foundation for ours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0390e0-39b2-4195-ad2f-812380c2cd53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9884bf50-260b-4858-bfd8-ada681bba06e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\987\\anaconda3\\envs\\main_ide\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\987\\anaconda3\\envs\\main_ide\\lib\\site-packages (from BeautifulSoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f49984-3e39-42b0-a9d1-68c9b1a8a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use BeautifulSoup to parse Weather Underground's HTML\n",
    "\n",
    "def getWeather(airport):\n",
    "    from urllib.request import urlopen\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    # set a the value that will store the daily weather\n",
    "    daily_weather = pd.DataFrame()\n",
    "\n",
    "    #Iterate through each days between 1 Jan 2018 and 31 Jan 2020\n",
    "    for year in range(2018,2020):\n",
    "        for m in range(1,13):\n",
    "            for d in range(1,32):\n",
    "\n",
    "                #Check if leap year\n",
    "                if year%4 == 0:\n",
    "                    leap = True\n",
    "                elif year%100 == 0:\n",
    "                    leap = False\n",
    "                elif year%400 == 0:\n",
    "                    leap = True\n",
    "                else:\n",
    "                    leap = False\n",
    "\n",
    "                #Check if already already gone through the month\n",
    "                if (m == 2 and leap and d>29):\n",
    "                    continue\n",
    "                elif (m == 2 and not leap and d>28):\n",
    "                    continue\n",
    "                elif (m in [4,6,9,11] and d>30): #original had 10 instead of 11, but 11 is correct (november has 30 days, not october)\n",
    "                    continue\n",
    "\n",
    "                # Open the URL and read the HTML\n",
    "                url = \"https://www.wunderground.com/history/daily/us/ny/new-york-city/K{}/date/{}-{}-{}\".format(airport,year,m,d)\n",
    "                page = urlopen(url).read()\n",
    "\n",
    "                # Get temperature\n",
    "                soup = BeautifulSoup(page)\n",
    "                dayTemp = soup.body.nobr.b.string\n",
    "\n",
    "                # Add to dataframe\n",
    "                daily_weather = daily_weather.append({'Date': \"{}-{}-{}\".format(year,m,d), 'Temp': dayTemp, 'Airport': airport}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbb90f13-b006-46a7-9db9-a70efb087d25",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgetWeather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRDU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mgetWeather\u001b[1;34m(airport)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Get temperature\u001b[39;00m\n\u001b[0;32m     38\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page)\n\u001b[1;32m---> 39\u001b[0m dayTemp \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnobr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m\u001b[38;5;241m.\u001b[39mstring\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Add to dataframe\u001b[39;00m\n\u001b[0;32m     42\u001b[0m daily_weather \u001b[38;5;241m=\u001b[39m daily_weather\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(year,m,d), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemp\u001b[39m\u001b[38;5;124m'\u001b[39m: dayTemp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirport\u001b[39m\u001b[38;5;124m'\u001b[39m: airport}, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'b'"
     ]
    }
   ],
   "source": [
    "getWeather('RDU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d8fd00-9ba9-4548-a5cb-9c4d78089517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main_IDE",
   "language": "python",
   "name": "main_ide"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
