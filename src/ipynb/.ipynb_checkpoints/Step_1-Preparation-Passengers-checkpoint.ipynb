{
 "cells": [
  {
   "cell_type": "raw",
   "id": "24e4392d-c2ac-4da4-ad45-c3071f03467f",
   "metadata": {},
   "source": [
    "# Import Flights table you want to enrich\n",
    "flights_sample = pd.read_csv(\"../../data/processed/flights_sample.csv\", index_col=False)\n",
    "\n",
    "# Create routeid column (used to add enrichment)\n",
    "flights_sample['routeid'] = flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "\n",
    "# Import passengers table\n",
    "passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed_groupedbyMonth(29Nov).csv\", index_col=False)\n",
    "\n",
    "# Adding the enrichment\n",
    "flights_sample = flights_sample.merge(passengers, on=\"routeid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89ca15-6b96-491f-b08e-7a7cb850967d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Function Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd4687-871c-4a5c-aa42-7e84b8ef7544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataCleaning(df, code=True, tips=False, orientation=True, formatIssues=True, missingValues=True, duplicateValues=True, outliers=True):\n",
    "    \"\"\"\n",
    "    df: your dataframe\n",
    "\n",
    "    code: A text template to note your observations as you go. Use the code snippets included in the output. copy-paste into vscode/notepad\n",
    "\n",
    "    tips: Provides snippets of code to help you clean potential issues in your df. If you prefer this to code\n",
    "    \n",
    "    orientation: Provides information about the shape/objects of your data\n",
    "    \n",
    "    formatIssues: Provides detailed information on each column to help identify format issues\n",
    "    \n",
    "    missingValues: Provides information on missing values\n",
    "    \n",
    "    duplicateValues: Provides information on duplicate values\n",
    "    \n",
    "    outliers: Provides information on outliers\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    if code==True:\n",
    "        print(\"### CLEANING CODE:\")\n",
    "        print(\"df = dfX #Change to your df's name\")\n",
    "        print()\n",
    "        print(\"#### Change column value:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Drop entire column:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Change column type:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Change column name:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Handle missing values:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Handle duplicate values:\")\n",
    "        print(\"# df.drop_duplicates(inplace=True) # drop ALL duplicate rows\")\n",
    "        print()\n",
    "        print(\"#### Drop outliers:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Other observations / further investigations:\")\n",
    "        print(\"#\")\n",
    "        print(\"#\")\n",
    "        print(\"#\")\n",
    "        print()\n",
    "        print(\"df.head() #Final Review\")\n",
    "        print(\"# dfX = df #Change to your df's name\")\n",
    "        print()\n",
    "        print(\"=========================================\")\n",
    "    \n",
    "    if orientation==True:\n",
    "        print(\"ORIENTATION\")\n",
    "        print(df.info())\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    if formatIssues==True:\n",
    "        print(\"FORMAT ISSUES\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object' or df[col].dtype == 'int64' or df[col].dtype == 'float64' or df[col].dtype == 'datetime64':\n",
    "            #if df[col].dtype == 'float64':\n",
    "\n",
    "                print(\"df.rename(columns={'\" + col + \"': ''}, inplace=True)\", \"#rename column\")\n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].replace('old_value', 'new_value')\")\n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].astype('new_type') # new_type can be int64, float64, object, category, datetime64\")\n",
    "                print(\"df.drop('\" + col + \"', axis=1, inplace=True)\")                \n",
    "                pd.set_option('display.max_rows', None)\n",
    "                print(df.groupby(col, sort=True).size())\n",
    "                pd.reset_option('display.max_rows')\n",
    "                #display the dtypes of the column\n",
    "                print(\"Current Column DType: \", df[col].dtype, \"     Do not compare with above. This one will always return int64 as it's the dtype of the count\")                \n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].astype('new_type') # new_type can be int64, float64, object, category, datetime64\")\n",
    "                print()\n",
    "            #else:\n",
    "            #    print(col)\n",
    "            #    print(df[col].describe())\n",
    "            #    print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"To make a correction to a column, use the following syntax:\")\n",
    "            print(\"df['A'] = df['A'].apply(lambda x: x.replace('old_value', 'new_value'))\")\n",
    "            print()\n",
    "            print(\"To change a column data type, use the following syntax:\")\n",
    "            print(\"df['A'] = pd.to_datetime(df['A']) # for datetime\")\n",
    "            print(\"df['A'] = df['A'].astype('int64') # for integers\")\n",
    "            print(\"df['A'] = df['A'].astype('float64') # for floats\")\n",
    "            print(\"df['A'] = df['A'].astype('category') # for categorical\")\n",
    "            print(\"df['A'] = df['A'].astype('object') # for object\")\n",
    "            print()\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if missingValues==True:\n",
    "        print(\"MISSING VALUES\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                print(col, \":\", df[col].isnull().sum(), \" missing values\")\n",
    "                print(\"df.dropna(subset=['\" + col + \"'], inplace=True)\")\n",
    "                print(\"df['\" + col + \"'].fillna(df['\" + col + \"'].mean(), inplace=True) #fill NA entries with the mean\")\n",
    "                print(\"df['\" + col + \"'].fillna(0, inplace=True) # fill NA entries with a single value, such as zero\")\n",
    "                print()\n",
    "                print(df.loc[df[col].isnull()].head())\n",
    "                print()\n",
    "            else:\n",
    "                print(col, \": No missing values\")\n",
    "                print()\n",
    "                                    \n",
    "        if tips==True:\n",
    "            print()\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop rows with missing values using one of the following code:\")\n",
    "            print(\"df.dropna(subset=['col'], inplace=True) #For a single column\")\n",
    "            print(\"df.dropna(inplace=True) #For all columns\")\n",
    "            print()\n",
    "            print(\"You can fill rows with missing values using one of the following code:\")\n",
    "            print(\"df['col'].fillna(df['col'].mean(), inplace=True) #fill NA entries with the mean\")\n",
    "            print(\"df['col'].fillna(0, inplace=True) # fill NA entries with a single value, such as zero\")\n",
    "            print(\"df['col'].fillna(method='ffill') # forward-fill to propagate the previous value forward\")\n",
    "            print(\"df['col'].fillna(method='bfill' # back-fill to propagate the next values backward)\")\n",
    "            print()\n",
    "            print(\"To view them:\")\n",
    "            print(\"df.loc[df[col].isnull()].head()\")\n",
    "            print()\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if duplicateValues==True:\n",
    "        print(\"DUPLICATE VALUES\")\n",
    "        print()\n",
    "        print(df[df.duplicated()].head())\n",
    "        print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop duplicate rows using the following code:\")\n",
    "            print(\"df.drop_duplicates(inplace=True)\")\n",
    "            print(\"df.drop_duplicates(subset=['col'], inplace=True) #For a single column\")\n",
    "            print()\n",
    "            print(\"To view them:\")\n",
    "            print(\"df[df.duplicated()].head()\")\n",
    "            print()\n",
    "    \n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if outliers==True:\n",
    "        print(\"OUTLIERS\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'int64' or df[col].dtype == 'float64':\n",
    "                print(col)\n",
    "                print(\"-----\")\n",
    "                print(\"Outlier(s):\")\n",
    "                print(\"Below \", df[col].mean() - 3*df[col].std(), \" -> \", df[df[col] < df[col].mean() - 3*df[col].std()].shape[0], \" low outlier(s)\")\n",
    "                print(\"Above \", df[col].mean() + 3*df[col].std(), \" -> \", df[df[col] > df[col].mean() + 3*df[col].std()].shape[0], \" high outlier(s)\")\n",
    "                low = df[col].mean() - 3*df[col].std()\n",
    "                high = df[col].mean() + 3*df[col].std()\n",
    "                print(\"df = df[(df['\" + col + \"'] > \" + str(low) + \") & (df['\" + col + \"'] < \" + str(high) + \")]\")\n",
    "                print()\n",
    "                print(df[col].describe())\n",
    "                print()\n",
    "                print(\"Boxplot\")\n",
    "                sns.boxplot(df[col])\n",
    "                plt.show()\n",
    "                print()\n",
    "                print(\"Histogram\")\n",
    "                sns.histplot(df[col])\n",
    "                plt.show()\n",
    "                print(\"=========================================\")\n",
    "                print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop outliers using the following code:\")\n",
    "            print(\"df = df[(df['column'] > lower_bound) & (df['column'] < upper_bound)]\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48072217-c0ed-4657-9610-c3cca8d87556",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd2116-e279-405d-a4e9-b48c6dabb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2ce1c-0b79-4965-b838-8cf4e962db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_sample = pd.read_csv(\"../../data/raw/flights_sample+test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e2e5e-18a9-4695-9682-22c0f9e331e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed(29Nov).csv\") \n",
    "## In the first step noticed this was not properly done (see Take 1 - Archived) so made the new one below.\n",
    "## Uncomment above and switch the cells in Take 1 archived to code for further details\n",
    "\n",
    "passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed_groupedbyMonth(29Nov).csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89cad7a9-3341-4787-af79-0f738b8fce02",
   "metadata": {},
   "source": [
    "passengers:\n",
    "\n",
    "This CSV was produced using the following SQL Query on the passengers table:\n",
    "\n",
    "SELECT CONCAT(year, '_', month, '-', unique_carrier, '-', origin, '-', dest) AS routeId\n",
    "\t, payload / departures_performed AS averagePayload_lbs\n",
    "\t, freight / departures_performed AS averageFreight_lbs\n",
    "\t, mail / departures_performed AS averageMail_lbs\n",
    "\t, seats / departures_performed AS availableSeats\n",
    "\t, passengers / departures_performed AS averagePassengers\n",
    "\t--, passengers / seats * 100 AS averageSeatsoccupied_perc\n",
    "\t, aircraft_group AS aircraftGroup\n",
    "\t, aircraft_type AS aircraftType\n",
    "\t, aircraft_config AS aircraftConfiguration\n",
    "\t, distance_group AS distanceInterval_x500mi\n",
    "\t, class AS serviceClass\n",
    "FROM passengers\n",
    "WHERE departures_performed > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387dac4-524f-4ed7-a30f-204fff3084c5",
   "metadata": {},
   "source": [
    "# Deciding on the Route ID column (will be used to merge with flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c045-9227-414a-9931-72f564c2d766",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Take 1 (dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7896b38-87b6-4d55-917f-8ce045807362",
   "metadata": {},
   "source": [
    "The passengers table is huge, it likely has information on routes that we don't need. Let's slim it down"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5278731d-1546-4a44-8722-cbb6b9e5721d",
   "metadata": {},
   "source": [
    "passengers.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1dacb895-7fa3-403f-9f1d-48fceb362979",
   "metadata": {},
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Flight Year'].astype(str) + '_' + flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Flight Year'].astype(str) + '_' + flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b900b9b-9303-4f4c-b065-eed83f24f8e7",
   "metadata": {},
   "source": [
    "Made 2x version, as not sure if the passengers' table is referring to the Operator or the Marketer.. we'll test both"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd32ce78-7440-4ac1-8e26-a50fe5ff981c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "flight_mkt = pd.DataFrame()\n",
    "unique_passengers = pd.DataFrame() \n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd40897-3241-40e6-9e7b-86ccf67904b0",
   "metadata": {},
   "source": [
    "Ok so the Flight Operator has more results, let's see the route that are not in the passengers table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3e3cda4-e34f-4ddd-803e-ce4aab29db73",
   "metadata": {},
   "source": [
    "print(flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711122f-fe74-489f-a43e-ba5c9f7bdb4d",
   "metadata": {},
   "source": [
    "This just made me notice something.. we don't have the data for 2020.. so we need to consolidate this information on a monthly thing. We'll need to reformat our route_ID to MM-carrier-origin-dest and then group the info of every year to either an average or a min/max where appropriate.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68358ceb-224e-410b-9ec3-dcbb7c337984",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Take 2 (dropped)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b24a13f7-90a4-4d0c-938d-6ea829d24c01",
   "metadata": {},
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a64ad44-d897-4cdc-91cc-2c41d6b61fa3",
   "metadata": {},
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "flight_mkt = pd.DataFrame()\n",
    "unique_passengers = pd.DataFrame() \n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b40e7-7346-4327-a21a-cdbe63308e13",
   "metadata": {},
   "source": [
    "Ok so the Flight Operator has more results, let's see the route that are not in the passengers table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7d58e77-d49e-40e0-a6e5-049ce68ae994",
   "metadata": {},
   "source": [
    "print(flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f55d2f-b537-4e6e-8a34-7f1ad50b891a",
   "metadata": {},
   "source": [
    "Ok, it looks like a fair amount is from our test... let's see..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0ced633-effd-416e-9741-be066b1dee32",
   "metadata": {},
   "source": [
    "count = flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])]\n",
    "count['Flight Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23d1e0-4dc2-46d0-a3b6-7ee38101c322",
   "metadata": {},
   "source": [
    "This is disappointing.. this probably means that we have new routes in our test.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda159c-6419-48e4-a2dc-fd204d9de8b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Take 3 - Month-depart-arrival (dropped)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7b1cd63-969a-4c13-b8f7-e89721cf3e4e",
   "metadata": {},
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_v3'] = flights_sample['Flight Month'].astype(str) + '-' +  flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "## We just need one in this case"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb2d53d6-a250-4b2e-b761-75b136d231f9",
   "metadata": {},
   "source": [
    "# Remove the carrier from the route ID column\n",
    "unique_passengers = pd.DataFrame()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "unique_passengers['routeid_month'] = unique_passengers['routeid'].str[:-11]\n",
    "unique_passengers['routeid_route'] = unique_passengers['routeid'].str[-8:]\n",
    "\n",
    "unique_passengers['routeid'] = unique_passengers['routeid_month'] + unique_passengers['routeid_route']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f796e-1695-4cc4-90f8-0767f80cb4ac",
   "metadata": {},
   "source": [
    "Let's see how this performs:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b22e85a-edcf-41ee-92d7-8d4efe60e023",
   "metadata": {},
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_v3'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flights\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Flight:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc00dba-cf2a-4c3b-8594-3e811f58c41e",
   "metadata": {},
   "source": [
    "This seems to perform better. Let's confirm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c00999c-ec86-4feb-abed-55cbd687839c",
   "metadata": {},
   "source": [
    "print(flights_sample[~flights_sample['routeId_v3'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_v3'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96f67e-2977-4c68-9470-02e1f5133a68",
   "metadata": {},
   "source": [
    "Still some missing from Jan 2020, damn!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b31cfef-d207-44f0-bda9-d1e06fd44975",
   "metadata": {},
   "source": [
    "count = flights_sample[~flights_sample['routeId_v3'].isin(unique_passengers['routeid'])]\n",
    "count['Flight Year'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c29bbc19-41bf-4753-a839-30b568c151cd",
   "metadata": {},
   "source": [
    "count['Flight Month'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c002e88-b3bf-411b-a41c-a6cd7071a232",
   "metadata": {},
   "source": [
    "flights_sample[(flights_sample['Flight Year'] == 2020) & (flights_sample['Flight Month'] == 1)].shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "909dfbe7-8869-4f08-bf89-76c859a07bfd",
   "metadata": {},
   "source": [
    "6741/660556*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68b6f1-3e96-477f-86c1-72e4aa92f60e",
   "metadata": {},
   "source": [
    "So we account for about 99% of the routes in January. It is better, but there is room for improvement. Also not a fan that we group all carriers together.. let's look at the other methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a924bb-d0b1-4d75-9ca7-a367bdb1313f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Take 4 - carrier-depart-arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c083c-ed3e-4ed8-a9b4-9176953e27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d770867-6d0c-43e0-8164-67563f8d7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the carrier from the route ID column\n",
    "unique_passengers = pd.DataFrame()\n",
    "\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "unique_passengers['routeid'] = unique_passengers['routeid'].str[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ac700-fa6b-41fd-ab01-7a8f138c1b8c",
   "metadata": {},
   "source": [
    "Let's see how this performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c9438-461b-4a84-ade0-84a80f921f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "flight_mkt = pd.DataFrame()\n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "\n",
    "## Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146bfde-0805-47af-8746-baa3a67327bd",
   "metadata": {},
   "source": [
    "This seems to perform better, and again Flight Operator is more commonly used. Let's confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f05b6-cd39-4546-988d-f4b97966dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93985bf-d821-49a1-8929-26affee5b805",
   "metadata": {},
   "source": [
    "Still some missing from Jan 2020, but we actually seem to have less this time. Let's confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735598d-0484-4130-ae09-25eec9f450db",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])]\n",
    "count['Flight Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b614433-b2bd-4a6d-a5d9-ebe2dff76008",
   "metadata": {},
   "outputs": [],
   "source": [
    "count['Flight Month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b251b5-3f29-4ef5-9678-7fb3cf916422",
   "metadata": {},
   "source": [
    "it is better, but there is room for improvement, let's look at the other methods. Also not a fan that we group all carriers together.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2427452-502f-4c0d-97f3-b4abf586e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_sample[(flights_sample['Flight Year'] == 2020) & (flights_sample['Flight Month'] == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb8faa-8b9a-43af-bfaf-166022312cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "993/660556*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63635cb0-e8c0-4696-9955-7e7f2d3b8c0d",
   "metadata": {},
   "source": [
    "Okay, the proportion is almost negligible at this point We account for 99.85% of the routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5aeb47-6ca8-40fc-a871-a1385590e594",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Grouping the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a5fea-71e6-40e4-80d8-48749844bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the duplicates\n",
    "\n",
    "passengers['routeid'] = passengers['routeid'].str[-10:]\n",
    "\n",
    "\n",
    "print(\"Total rows:\", passengers['routeid'].count())\n",
    "print(\"Unique values:\", passengers['routeid'].nunique())\n",
    "print(\"Duplicate values:\", passengers['routeid'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4536d6f3-555f-41e2-8ee7-a60c5dc00498",
   "metadata": {},
   "source": [
    "So each rows have about 5-6x values.. we'll group them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2413f83-ec80-47be-8458-b088b45c25d4",
   "metadata": {},
   "source": [
    "Before we group them, let's calculate the Freight ratio, the Mail Ratio as well as the amount of SeatOccupied, it will be more accurate than calculating once they are merged together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4ab77-fe97-4e9d-8e09-415cbd7546db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 0s seem the be throwing off our calculations.. we'll switch them to NaNs\n",
    "passengers['availableseats'] = passengers['availableseats'].replace(0, np.nan)\n",
    "passengers['averagepassengers'] = passengers['averagepassengers'].replace(0, np.nan)\n",
    "passengers['averagepayload_lbs'] = passengers['averagepayload_lbs'].replace(0, np.nan)\n",
    "passengers['averagefreight_lbs'] = passengers['averagefreight_lbs'].replace(0, np.nan)\n",
    "passengers['averagemail_lbs'] = passengers['averagemail_lbs'].replace(0, np.nan)\n",
    "\n",
    "passengers['Proportion of freight to the payload'] = passengers['averagefreight_lbs'] / passengers['averagepayload_lbs']\n",
    "passengers['Proportion of mail to the payload'] = passengers['averagemail_lbs'] / passengers['averagepayload_lbs']\n",
    "passengers['Proportion of filled seats'] = passengers['averagepassengers'] / passengers['availableseats']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8eebd-fb09-4acc-b85c-76dd6c9ac270",
   "metadata": {},
   "source": [
    "We will group by routeid and avg the values for averagepayload_lbs, averagefreight_lbs, averagemail_lbs, availableseats, averagepassengers, distanceinterval_x500mi \n",
    "\n",
    "As well, aircraftgroup, aircrafttype, aircraftconfiguration, and serviceclass are all categorical variables, so we'll take the most common value for each group and return UNK if we don't have the info\n",
    "\n",
    "We're putting the grouping results into grouped_passengers, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3584f523-f19d-4eed-91ee-0bf20f95b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers['aircraftgroup'] = passengers['aircraftgroup'].replace(0, 'UNK') #The zeros are assessed to be NANs in this column\n",
    "passengers['aircrafttype'] = passengers['aircrafttype'].replace(0, 'UNK') #The zeros are assessed to be NANs in this column\n",
    "passengers['serviceclass'].fillna('UNK', inplace=True)\n",
    "\n",
    "grouped_passengers = passengers.groupby(['routeid']).agg({'Proportion of freight to the payload': 'mean', 'Proportion of mail to the payload': 'mean', 'Proportion of filled seats': 'mean', 'averagepayload_lbs': 'mean', 'availableseats': 'mean', 'distanceinterval_x500mi': 'mean', 'aircraftgroup': lambda x: x.value_counts().index[1] if x.value_counts().index[0] == 'UNK' and len(x.value_counts()) > 1 else x.value_counts().index[0], 'aircrafttype': lambda x: x.value_counts().index[1] if x.value_counts().index[0] == 'UNK' and len(x.value_counts()) > 1 else x.value_counts().index[0], 'aircraftconfiguration': lambda x: x.value_counts().index[0], 'serviceclass': lambda x: x.value_counts().index[1] if x.value_counts().index[0] == 'UNK' and len(x.value_counts()) > 1 else x.value_counts().index[0]}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f74615-8db1-4ed9-ace7-934236cc4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(passengers.shape)\n",
    "print(grouped_passengers.shape)\n",
    "grouped_passengers.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88857c-55b1-4f3b-836c-15424580f961",
   "metadata": {},
   "source": [
    "And we're matching our unique values from above.. TRIPLE BAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce557b-199e-4e7b-b724-c61566d53390",
   "metadata": {},
   "source": [
    "# Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018bae6e-d55f-4096-b489-fb0b49c9e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_passengers.to_csv(\"../../data/processed/flights_enrichment_avgpayload_passengers.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
