{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd89ca15-6b96-491f-b08e-7a7cb850967d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Function Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd4687-871c-4a5c-aa42-7e84b8ef7544",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataCleaning(df, code=True, tips=False, orientation=True, formatIssues=True, missingValues=True, duplicateValues=True, outliers=True):\n",
    "    \"\"\"\n",
    "    df: your dataframe\n",
    "\n",
    "    code: A text template to note your observations as you go. Use the code snippets included in the output. copy-paste into vscode/notepad\n",
    "\n",
    "    tips: Provides snippets of code to help you clean potential issues in your df. If you prefer this to code\n",
    "    \n",
    "    orientation: Provides information about the shape/objects of your data\n",
    "    \n",
    "    formatIssues: Provides detailed information on each column to help identify format issues\n",
    "    \n",
    "    missingValues: Provides information on missing values\n",
    "    \n",
    "    duplicateValues: Provides information on duplicate values\n",
    "    \n",
    "    outliers: Provides information on outliers\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    if code==True:\n",
    "        print(\"### CLEANING CODE:\")\n",
    "        print(\"df = dfX #Change to your df's name\")\n",
    "        print()\n",
    "        print(\"#### Change column value:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Drop entire column:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Change column type:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Change column name:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Handle missing values:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Handle duplicate values:\")\n",
    "        print(\"# df.drop_duplicates(inplace=True) # drop ALL duplicate rows\")\n",
    "        print()\n",
    "        print(\"#### Drop outliers:\")\n",
    "        print()\n",
    "        print()\n",
    "        print(\"#### Other observations / further investigations:\")\n",
    "        print(\"#\")\n",
    "        print(\"#\")\n",
    "        print(\"#\")\n",
    "        print()\n",
    "        print(\"df.head() #Final Review\")\n",
    "        print(\"# dfX = df #Change to your df's name\")\n",
    "        print()\n",
    "        print(\"=========================================\")\n",
    "    \n",
    "    if orientation==True:\n",
    "        print(\"ORIENTATION\")\n",
    "        print(df.info())\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    if formatIssues==True:\n",
    "        print(\"FORMAT ISSUES\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object' or df[col].dtype == 'int64' or df[col].dtype == 'float64' or df[col].dtype == 'datetime64':\n",
    "            #if df[col].dtype == 'float64':\n",
    "\n",
    "                print(\"df.rename(columns={'\" + col + \"': ''}, inplace=True)\", \"#rename column\")\n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].replace('old_value', 'new_value')\")\n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].astype('new_type') # new_type can be int64, float64, object, category, datetime64\")\n",
    "                print(\"df.drop('\" + col + \"', axis=1, inplace=True)\")                \n",
    "                pd.set_option('display.max_rows', None)\n",
    "                print(df.groupby(col, sort=True).size())\n",
    "                pd.reset_option('display.max_rows')\n",
    "                #display the dtypes of the column\n",
    "                print(\"Current Column DType: \", df[col].dtype, \"     Do not compare with above. This one will always return int64 as it's the dtype of the count\")                \n",
    "                print(\"df['\" + col + \"'] = df['\" + col + \"'].astype('new_type') # new_type can be int64, float64, object, category, datetime64\")\n",
    "                print()\n",
    "            #else:\n",
    "            #    print(col)\n",
    "            #    print(df[col].describe())\n",
    "            #    print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"To make a correction to a column, use the following syntax:\")\n",
    "            print(\"df['A'] = df['A'].apply(lambda x: x.replace('old_value', 'new_value'))\")\n",
    "            print()\n",
    "            print(\"To change a column data type, use the following syntax:\")\n",
    "            print(\"df['A'] = pd.to_datetime(df['A']) # for datetime\")\n",
    "            print(\"df['A'] = df['A'].astype('int64') # for integers\")\n",
    "            print(\"df['A'] = df['A'].astype('float64') # for floats\")\n",
    "            print(\"df['A'] = df['A'].astype('category') # for categorical\")\n",
    "            print(\"df['A'] = df['A'].astype('object') # for object\")\n",
    "            print()\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if missingValues==True:\n",
    "        print(\"MISSING VALUES\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                print(col, \":\", df[col].isnull().sum(), \" missing values\")\n",
    "                print(\"df.dropna(subset=['\" + col + \"'], inplace=True)\")\n",
    "                print(\"df['\" + col + \"'].fillna(df['\" + col + \"'].mean(), inplace=True) #fill NA entries with the mean\")\n",
    "                print(\"df['\" + col + \"'].fillna(0, inplace=True) # fill NA entries with a single value, such as zero\")\n",
    "                print()\n",
    "                print(df.loc[df[col].isnull()].head())\n",
    "                print()\n",
    "            else:\n",
    "                print(col, \": No missing values\")\n",
    "                print()\n",
    "                                    \n",
    "        if tips==True:\n",
    "            print()\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop rows with missing values using one of the following code:\")\n",
    "            print(\"df.dropna(subset=['col'], inplace=True) #For a single column\")\n",
    "            print(\"df.dropna(inplace=True) #For all columns\")\n",
    "            print()\n",
    "            print(\"You can fill rows with missing values using one of the following code:\")\n",
    "            print(\"df['col'].fillna(df['col'].mean(), inplace=True) #fill NA entries with the mean\")\n",
    "            print(\"df['col'].fillna(0, inplace=True) # fill NA entries with a single value, such as zero\")\n",
    "            print(\"df['col'].fillna(method='ffill') # forward-fill to propagate the previous value forward\")\n",
    "            print(\"df['col'].fillna(method='bfill' # back-fill to propagate the next values backward)\")\n",
    "            print()\n",
    "            print(\"To view them:\")\n",
    "            print(\"df.loc[df[col].isnull()].head()\")\n",
    "            print()\n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if duplicateValues==True:\n",
    "        print(\"DUPLICATE VALUES\")\n",
    "        print()\n",
    "        print(df[df.duplicated()].head())\n",
    "        print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop duplicate rows using the following code:\")\n",
    "            print(\"df.drop_duplicates(inplace=True)\")\n",
    "            print(\"df.drop_duplicates(subset=['col'], inplace=True) #For a single column\")\n",
    "            print()\n",
    "            print(\"To view them:\")\n",
    "            print(\"df[df.duplicated()].head()\")\n",
    "            print()\n",
    "    \n",
    "        print(\"=========================================\")\n",
    "        print()\n",
    "\n",
    "    if outliers==True:\n",
    "        print(\"OUTLIERS\")\n",
    "        print()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'int64' or df[col].dtype == 'float64':\n",
    "                print(col)\n",
    "                print(\"-----\")\n",
    "                print(\"Outlier(s):\")\n",
    "                print(\"Below \", df[col].mean() - 3*df[col].std(), \" -> \", df[df[col] < df[col].mean() - 3*df[col].std()].shape[0], \" low outlier(s)\")\n",
    "                print(\"Above \", df[col].mean() + 3*df[col].std(), \" -> \", df[df[col] > df[col].mean() + 3*df[col].std()].shape[0], \" high outlier(s)\")\n",
    "                low = df[col].mean() - 3*df[col].std()\n",
    "                high = df[col].mean() + 3*df[col].std()\n",
    "                print(\"df = df[(df['\" + col + \"'] > \" + str(low) + \") & (df['\" + col + \"'] < \" + str(high) + \")]\")\n",
    "                print()\n",
    "                print(df[col].describe())\n",
    "                print()\n",
    "                print(\"Boxplot\")\n",
    "                sns.boxplot(df[col])\n",
    "                plt.show()\n",
    "                print()\n",
    "                print(\"Histogram\")\n",
    "                sns.histplot(df[col])\n",
    "                plt.show()\n",
    "                print(\"=========================================\")\n",
    "                print()\n",
    "\n",
    "        if tips==True:\n",
    "            print(\"TIPS\")\n",
    "            print(\"You can drop outliers using the following code:\")\n",
    "            print(\"df = df[(df['column'] > lower_bound) & (df['column'] < upper_bound)]\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48072217-c0ed-4657-9610-c3cca8d87556",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00cd2116-e279-405d-a4e9-b48c6dabb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "964e2e5e-18a9-4695-9682-22c0f9e331e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flights_sample = pd.read_csv(\"../../data/processed/flights_sample.csv\")\n",
    "\n",
    "#passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed(29Nov).csv\") #In the first step noticed this was not properly done so made the new one below\n",
    "passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed_groupedbyMonth(29Nov).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e0ef89-40b2-468f-a6fc-2c07088e621b",
   "metadata": {},
   "source": [
    "passengers:\n",
    "\n",
    "This CSV was produced using the following SQL Query:\n",
    "\n",
    "SELECT CONCAT(year, '_', month, '-', unique_carrier, '-', origin, '-', dest) AS routeId\n",
    "\t, payload / departures_performed AS averagePayload_lbs\n",
    "\t, freight / departures_performed AS averageFreight_lbs\n",
    "\t, mail / departures_performed AS averageMail_lbs\n",
    "\t, seats / departures_performed AS availableSeats\n",
    "\t, passengers / departures_performed AS averagePassengers\n",
    "\t--, passengers / seats * 100 AS averageSeatsoccupied_perc\n",
    "\t, aircraft_group AS aircraftGroup\n",
    "\t, aircraft_type AS aircraftType\n",
    "\t, aircraft_config AS aircraftConfiguration\n",
    "\t, distance_group AS distanceInterval_x500mi\n",
    "\t, class AS serviceClass\n",
    "FROM passengers\n",
    "WHERE departures_performed > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c045-9227-414a-9931-72f564c2d766",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Keep only relevant rows (Take 1 - Archived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7896b38-87b6-4d55-917f-8ce045807362",
   "metadata": {},
   "source": [
    "The passengers table is huge, it likely has information on routes that we don't need. Let's slim it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54331d17-2cad-4c44-89fc-9fcf38ebc672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2334701, 11)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c204b73-75fb-4c78-81c8-85bf0a24af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Flight Year'].astype(str) + '_' + flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Flight Year'].astype(str) + '_' + flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b900b9b-9303-4f4c-b065-eed83f24f8e7",
   "metadata": {},
   "source": [
    "Made 2x version, as not sure if the passengers' table is referring to the Operator or the Marketer.. we'll test both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f48a0c5-f041-4f0d-b9c0-5276d2db654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight Operator\n",
      "Total: 112012\n",
      "In passenger: 111997\n",
      "\n",
      "Flight Marketer\n",
      "Total: 102429\n",
      "In passenger: 72961\n",
      "\n",
      "Passengers Table\n",
      "Total: 1479024\n",
      "In Marketer: 72961\n",
      "In Operator: 111997\n"
     ]
    }
   ],
   "source": [
    "# List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "#flight_op = pd.DataFrame()\n",
    "#flight_mkt = pd.DataFrame()\n",
    "#unique_passengers = pd.DataFrame() \n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "# Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd40897-3241-40e6-9e7b-86ccf67904b0",
   "metadata": {},
   "source": [
    "Ok so the Flight Operator has more results, let's see the route that are not in the passengers table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65a9ed84-d60b-49b2-8bd7-6c9932b18ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 39)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flight Year</th>\n",
       "      <th>Flight Month</th>\n",
       "      <th>Flight Day</th>\n",
       "      <th>Flight Weekday</th>\n",
       "      <th>Marketer - Unique Carrier Code</th>\n",
       "      <th>Operator - Unique Carrier Code</th>\n",
       "      <th>Different Marketer &amp; Operator Carrier Code</th>\n",
       "      <th>Tail Number</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Origin Airport (ID)</th>\n",
       "      <th>Origin Airport (IATA Code)</th>\n",
       "      <th>Origin Airport (City, State)</th>\n",
       "      <th>Destination Airport (ID)</th>\n",
       "      <th>Destination Airport (IATA Code)</th>\n",
       "      <th>Destination Airport (City, State)</th>\n",
       "      <th>Departure Delay (minutes)</th>\n",
       "      <th>Arrival Delay (minutes)</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Cancellation Code</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>Scheduled Departure Time (local time)</th>\n",
       "      <th>Actual Departure Time (local time)</th>\n",
       "      <th>Taxi Out (minutes)</th>\n",
       "      <th>Wheels Off (local time)</th>\n",
       "      <th>Wheels On (local time)</th>\n",
       "      <th>Taxi In (minutes)</th>\n",
       "      <th>Scheduled Arrival Time (local time)</th>\n",
       "      <th>Actual Arrival Time (local time)</th>\n",
       "      <th>Scheduled Elapsed Time</th>\n",
       "      <th>Actual Elapsed Time</th>\n",
       "      <th>Air Time</th>\n",
       "      <th>Distance (miles)</th>\n",
       "      <th>Carrier Delay (minutes)</th>\n",
       "      <th>Weather Delay (minutes)</th>\n",
       "      <th>National Air System Delay (minutes)</th>\n",
       "      <th>Security Delay (minutes)</th>\n",
       "      <th>Late Aircraft Delay (minutes)</th>\n",
       "      <th>routeId_op</th>\n",
       "      <th>routeId_mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N806HC</td>\n",
       "      <td>648</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>12492</td>\n",
       "      <td>JHM</td>\n",
       "      <td>Kapalua, HI</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20:21</td>\n",
       "      <td>20:18</td>\n",
       "      <td>00:12</td>\n",
       "      <td>20:30</td>\n",
       "      <td>20:53</td>\n",
       "      <td>00:03</td>\n",
       "      <td>20:59</td>\n",
       "      <td>20:56</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_11-EM-HNL-JHM</td>\n",
       "      <td>2019_11-HA-HNL-JHM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10742</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N801HC</td>\n",
       "      <td>673</td>\n",
       "      <td>13347</td>\n",
       "      <td>MKK</td>\n",
       "      <td>Hoolehua, HI</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>06:43</td>\n",
       "      <td>09:25</td>\n",
       "      <td>00:03</td>\n",
       "      <td>09:28</td>\n",
       "      <td>09:46</td>\n",
       "      <td>00:08</td>\n",
       "      <td>07:52</td>\n",
       "      <td>09:54</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>2019_11-EM-MKK-HNL</td>\n",
       "      <td>2019_11-HA-MKK-HNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14230</th>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>NK</td>\n",
       "      <td>NK</td>\n",
       "      <td>0</td>\n",
       "      <td>N627NK</td>\n",
       "      <td>1455</td>\n",
       "      <td>10529</td>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>15304</td>\n",
       "      <td>TPA</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>-11</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18:40</td>\n",
       "      <td>18:29</td>\n",
       "      <td>00:10</td>\n",
       "      <td>18:39</td>\n",
       "      <td>22:31</td>\n",
       "      <td>00:05</td>\n",
       "      <td>23:39</td>\n",
       "      <td>22:36</td>\n",
       "      <td>179</td>\n",
       "      <td>167</td>\n",
       "      <td>152</td>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018_9-NK-BDL-TPA</td>\n",
       "      <td>2018_9-NK-BDL-TPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17621</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N804HC</td>\n",
       "      <td>610</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>13347</td>\n",
       "      <td>MKK</td>\n",
       "      <td>Hoolehua, HI</td>\n",
       "      <td>-7</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10:55</td>\n",
       "      <td>10:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:05</td>\n",
       "      <td>11:54</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018_10-EM-HNL-MKK</td>\n",
       "      <td>2018_10-HA-HNL-MKK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18445</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N804HC</td>\n",
       "      <td>654</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>12492</td>\n",
       "      <td>JHM</td>\n",
       "      <td>Kapalua, HI</td>\n",
       "      <td>-3</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>03:18</td>\n",
       "      <td>03:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04:36</td>\n",
       "      <td>04:28</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018_10-EM-HNL-JHM</td>\n",
       "      <td>2018_10-HA-HNL-JHM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37388</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>UA</td>\n",
       "      <td>EV</td>\n",
       "      <td>1</td>\n",
       "      <td>N13975</td>\n",
       "      <td>4152</td>\n",
       "      <td>13930</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>14100</td>\n",
       "      <td>PHL</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>13:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_3-EV-ORD-PHL</td>\n",
       "      <td>2019_3-UA-ORD-PHL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52425</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N805HC</td>\n",
       "      <td>653</td>\n",
       "      <td>13347</td>\n",
       "      <td>MKK</td>\n",
       "      <td>Hoolehua, HI</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>01:38</td>\n",
       "      <td>01:47</td>\n",
       "      <td>00:05</td>\n",
       "      <td>01:52</td>\n",
       "      <td>02:52</td>\n",
       "      <td>00:03</td>\n",
       "      <td>02:47</td>\n",
       "      <td>02:55</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_11-EM-MKK-HNL</td>\n",
       "      <td>2019_11-HA-MKK-HNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58174</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N804HC</td>\n",
       "      <td>611</td>\n",
       "      <td>13347</td>\n",
       "      <td>MKK</td>\n",
       "      <td>Hoolehua, HI</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>-12</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12:31</td>\n",
       "      <td>12:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13:39</td>\n",
       "      <td>13:31</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018_10-EM-MKK-HNL</td>\n",
       "      <td>2018_10-HA-MKK-HNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58898</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N804HC</td>\n",
       "      <td>613</td>\n",
       "      <td>13034</td>\n",
       "      <td>LNY</td>\n",
       "      <td>Lanai, HI</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15:49</td>\n",
       "      <td>18:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:01</td>\n",
       "      <td>18:51</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2018_10-EM-LNY-HNL</td>\n",
       "      <td>2018_10-HA-LNY-HNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68622</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>HA</td>\n",
       "      <td>EM</td>\n",
       "      <td>1</td>\n",
       "      <td>N801HC</td>\n",
       "      <td>645</td>\n",
       "      <td>13034</td>\n",
       "      <td>LNY</td>\n",
       "      <td>Lanai, HI</td>\n",
       "      <td>12173</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>-16</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20:05</td>\n",
       "      <td>19:09</td>\n",
       "      <td>00:07</td>\n",
       "      <td>19:16</td>\n",
       "      <td>20:17</td>\n",
       "      <td>00:04</td>\n",
       "      <td>20:40</td>\n",
       "      <td>20:21</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_11-EM-LNY-HNL</td>\n",
       "      <td>2019_11-HA-LNY-HNL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flight Year  Flight Month  Flight Day  Flight Weekday  \\\n",
       "1085          2019            11           5               1   \n",
       "10742         2019            11           3               6   \n",
       "14230         2018             9          21               4   \n",
       "17621         2018            10          16               1   \n",
       "18445         2018            10          28               6   \n",
       "37388         2019             3           3               6   \n",
       "52425         2019            11          19               1   \n",
       "58174         2018            10          16               1   \n",
       "58898         2018            10          15               0   \n",
       "68622         2019            11          12               1   \n",
       "\n",
       "      Marketer - Unique Carrier Code Operator - Unique Carrier Code  \\\n",
       "1085                              HA                             EM   \n",
       "10742                             HA                             EM   \n",
       "14230                             NK                             NK   \n",
       "17621                             HA                             EM   \n",
       "18445                             HA                             EM   \n",
       "37388                             UA                             EV   \n",
       "52425                             HA                             EM   \n",
       "58174                             HA                             EM   \n",
       "58898                             HA                             EM   \n",
       "68622                             HA                             EM   \n",
       "\n",
       "       Different Marketer & Operator Carrier Code Tail Number  Flight Number  \\\n",
       "1085                                            1      N806HC            648   \n",
       "10742                                           1      N801HC            673   \n",
       "14230                                           0      N627NK           1455   \n",
       "17621                                           1      N804HC            610   \n",
       "18445                                           1      N804HC            654   \n",
       "37388                                           1      N13975           4152   \n",
       "52425                                           1      N805HC            653   \n",
       "58174                                           1      N804HC            611   \n",
       "58898                                           1      N804HC            613   \n",
       "68622                                           1      N801HC            645   \n",
       "\n",
       "       Origin Airport (ID) Origin Airport (IATA Code)  \\\n",
       "1085                 12173                        HNL   \n",
       "10742                13347                        MKK   \n",
       "14230                10529                        BDL   \n",
       "17621                12173                        HNL   \n",
       "18445                12173                        HNL   \n",
       "37388                13930                        ORD   \n",
       "52425                13347                        MKK   \n",
       "58174                13347                        MKK   \n",
       "58898                13034                        LNY   \n",
       "68622                13034                        LNY   \n",
       "\n",
       "      Origin Airport (City, State)  Destination Airport (ID)  \\\n",
       "1085                  Honolulu, HI                     12492   \n",
       "10742                 Hoolehua, HI                     12173   \n",
       "14230                 Hartford, CT                     15304   \n",
       "17621                 Honolulu, HI                     13347   \n",
       "18445                 Honolulu, HI                     12492   \n",
       "37388                  Chicago, IL                     14100   \n",
       "52425                 Hoolehua, HI                     12173   \n",
       "58174                 Hoolehua, HI                     12173   \n",
       "58898                    Lanai, HI                     12173   \n",
       "68622                    Lanai, HI                     12173   \n",
       "\n",
       "      Destination Airport (IATA Code) Destination Airport (City, State)  \\\n",
       "1085                              JHM                       Kapalua, HI   \n",
       "10742                             HNL                      Honolulu, HI   \n",
       "14230                             TPA                         Tampa, FL   \n",
       "17621                             MKK                      Hoolehua, HI   \n",
       "18445                             JHM                       Kapalua, HI   \n",
       "37388                             PHL                  Philadelphia, PA   \n",
       "52425                             HNL                      Honolulu, HI   \n",
       "58174                             HNL                      Honolulu, HI   \n",
       "58898                             HNL                      Honolulu, HI   \n",
       "68622                             HNL                      Honolulu, HI   \n",
       "\n",
       "       Departure Delay (minutes)  Arrival Delay (minutes)  Cancelled  \\\n",
       "1085                          -3                       -3          0   \n",
       "10742                         82                       82          0   \n",
       "14230                        -11                      -23          0   \n",
       "17621                         -7                      -11          0   \n",
       "18445                         -3                       -8          0   \n",
       "37388                          0                        0          1   \n",
       "52425                          9                        8          0   \n",
       "58174                        -12                       -8          0   \n",
       "58898                         73                       70          0   \n",
       "68622                        -16                      -19          0   \n",
       "\n",
       "      Cancellation Code  Diverted Scheduled Departure Time (local time)  \\\n",
       "1085                NaN         0                                 20:21   \n",
       "10742               NaN         0                                 06:43   \n",
       "14230               NaN         0                                 18:40   \n",
       "17621               NaN         0                                 10:55   \n",
       "18445               NaN         0                                 03:18   \n",
       "37388                 A         0                                 13:20   \n",
       "52425               NaN         0                                 01:38   \n",
       "58174               NaN         0                                 12:31   \n",
       "58898               NaN         0                                 15:49   \n",
       "68622               NaN         0                                 20:05   \n",
       "\n",
       "      Actual Departure Time (local time) Taxi Out (minutes)  \\\n",
       "1085                               20:18              00:12   \n",
       "10742                              09:25              00:03   \n",
       "14230                              18:29              00:10   \n",
       "17621                              10:48                NaN   \n",
       "18445                              03:15                NaN   \n",
       "37388                                NaN                NaN   \n",
       "52425                              01:47              00:05   \n",
       "58174                              12:19                NaN   \n",
       "58898                              18:22                NaN   \n",
       "68622                              19:09              00:07   \n",
       "\n",
       "      Wheels Off (local time) Wheels On (local time) Taxi In (minutes)  \\\n",
       "1085                    20:30                  20:53             00:03   \n",
       "10742                   09:28                  09:46             00:08   \n",
       "14230                   18:39                  22:31             00:05   \n",
       "17621                     NaN                    NaN               NaN   \n",
       "18445                     NaN                    NaN               NaN   \n",
       "37388                     NaN                    NaN               NaN   \n",
       "52425                   01:52                  02:52             00:03   \n",
       "58174                     NaN                    NaN               NaN   \n",
       "58898                     NaN                    NaN               NaN   \n",
       "68622                   19:16                  20:17             00:04   \n",
       "\n",
       "      Scheduled Arrival Time (local time) Actual Arrival Time (local time)  \\\n",
       "1085                                20:59                            20:56   \n",
       "10742                               07:52                            09:54   \n",
       "14230                               23:39                            22:36   \n",
       "17621                               12:05                            11:54   \n",
       "18445                               04:36                            04:28   \n",
       "37388                               17:38                              NaN   \n",
       "52425                               02:47                            02:55   \n",
       "58174                               13:39                            13:31   \n",
       "58898                               17:01                            18:51   \n",
       "68622                               20:40                            20:21   \n",
       "\n",
       "       Scheduled Elapsed Time  Actual Elapsed Time  Air Time  \\\n",
       "1085                       38                   38        23   \n",
       "10742                      29                   29        18   \n",
       "14230                     179                  167       152   \n",
       "17621                      30                   26         0   \n",
       "18445                      38                   33         0   \n",
       "37388                     118                    0         0   \n",
       "52425                      29                   28        20   \n",
       "58174                      28                   32         0   \n",
       "58898                      32                   29         0   \n",
       "68622                      35                   32        21   \n",
       "\n",
       "       Distance (miles)  Carrier Delay (minutes)  Weather Delay (minutes)  \\\n",
       "1085                 84                        0                        0   \n",
       "10742                54                        3                        0   \n",
       "14230              1111                        0                        0   \n",
       "17621                54                        0                        0   \n",
       "18445                84                        0                        0   \n",
       "37388               678                        0                        0   \n",
       "52425                54                        0                        0   \n",
       "58174                54                        0                        0   \n",
       "58898                72                        0                        0   \n",
       "68622                72                        0                        0   \n",
       "\n",
       "       National Air System Delay (minutes)  Security Delay (minutes)  \\\n",
       "1085                                     0                         0   \n",
       "10742                                    0                         0   \n",
       "14230                                    0                         0   \n",
       "17621                                    0                         0   \n",
       "18445                                    0                         0   \n",
       "37388                                    0                         0   \n",
       "52425                                    0                         0   \n",
       "58174                                    0                         0   \n",
       "58898                                    0                         0   \n",
       "68622                                    0                         0   \n",
       "\n",
       "       Late Aircraft Delay (minutes)          routeId_op         routeId_mkt  \n",
       "1085                               0  2019_11-EM-HNL-JHM  2019_11-HA-HNL-JHM  \n",
       "10742                             79  2019_11-EM-MKK-HNL  2019_11-HA-MKK-HNL  \n",
       "14230                              0   2018_9-NK-BDL-TPA   2018_9-NK-BDL-TPA  \n",
       "17621                              0  2018_10-EM-HNL-MKK  2018_10-HA-HNL-MKK  \n",
       "18445                              0  2018_10-EM-HNL-JHM  2018_10-HA-HNL-JHM  \n",
       "37388                              0   2019_3-EV-ORD-PHL   2019_3-UA-ORD-PHL  \n",
       "52425                              0  2019_11-EM-MKK-HNL  2019_11-HA-MKK-HNL  \n",
       "58174                              0  2018_10-EM-MKK-HNL  2018_10-HA-MKK-HNL  \n",
       "58898                             70  2018_10-EM-LNY-HNL  2018_10-HA-LNY-HNL  \n",
       "68622                              0  2019_11-EM-LNY-HNL  2019_11-HA-LNY-HNL  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].shape)\n",
    "flights_sample[~flights_sample['routeId_op'].isin(unique_passengers['routeid'])].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711122f-fe74-489f-a43e-ba5c9f7bdb4d",
   "metadata": {},
   "source": [
    "This just made me notice something.. we don't have the data for 2020.. so we need to consolidate this information on a monthly thing. We'll need to reformat our route_ID to MM-carrier-origin-dest and then group the info of every year to either an average or a min/max where appropriate.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050fc67b-8f25-4976-ac59-ccd6a1656623",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tweaking the passengers table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5528042-b1cc-4785-a630-c75c96945b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>routeid</th>\n",
       "      <th>averagepayload_lbs</th>\n",
       "      <th>averagefreight_lbs</th>\n",
       "      <th>averagemail_lbs</th>\n",
       "      <th>availableseats</th>\n",
       "      <th>averagepassengers</th>\n",
       "      <th>aircraftgroup</th>\n",
       "      <th>aircrafttype</th>\n",
       "      <th>aircraftconfiguration</th>\n",
       "      <th>distanceinterval_x500mi</th>\n",
       "      <th>serviceclass</th>\n",
       "      <th>routeid_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019_6-LH-IAD-MUC</td>\n",
       "      <td>98368.6</td>\n",
       "      <td>6791.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>274.700000</td>\n",
       "      <td>6</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>F</td>\n",
       "      <td>6-LH-IAD-MUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019_6-LH-IAH-FRA</td>\n",
       "      <td>138113.8</td>\n",
       "      <td>13347.633333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>483.733333</td>\n",
       "      <td>8</td>\n",
       "      <td>882</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>F</td>\n",
       "      <td>6-LH-IAH-FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019_6-LH-IAH-FRA</td>\n",
       "      <td>187000.0</td>\n",
       "      <td>113393.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>740</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>G</td>\n",
       "      <td>6-LH-IAH-FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019_6-LH-JAX-ATL</td>\n",
       "      <td>187000.0</td>\n",
       "      <td>164936.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>740</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>6-LH-JAX-ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019_6-LH-JFK-FRA</td>\n",
       "      <td>107934.0</td>\n",
       "      <td>8802.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>819</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>F</td>\n",
       "      <td>6-LH-JFK-FRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             routeid  averagepayload_lbs  averagefreight_lbs  averagemail_lbs  \\\n",
       "0  2019_6-LH-IAD-MUC             98368.6         6791.700000              0.0   \n",
       "1  2019_6-LH-IAH-FRA            138113.8        13347.633333              0.0   \n",
       "2  2019_6-LH-IAH-FRA            187000.0       113393.000000              0.0   \n",
       "3  2019_6-LH-JAX-ATL            187000.0       164936.000000              0.0   \n",
       "4  2019_6-LH-JFK-FRA            107934.0         8802.000000              0.0   \n",
       "\n",
       "   availableseats  averagepassengers  aircraftgroup  aircrafttype  \\\n",
       "0           293.0         274.700000              6           359   \n",
       "1           509.0         483.733333              8           882   \n",
       "2             0.0           0.000000              7           740   \n",
       "3             0.0           0.000000              7           740   \n",
       "4           371.0         354.000000              8           819   \n",
       "\n",
       "   aircraftconfiguration  distanceinterval_x500mi serviceclass     routeid_2  \n",
       "0                      1                        9            F  6-LH-IAD-MUC  \n",
       "1                      1                       11            F  6-LH-IAH-FRA  \n",
       "2                      2                       11            G  6-LH-IAH-FRA  \n",
       "3                      2                        1            G  6-LH-JAX-ATL  \n",
       "4                      1                        8            F  6-LH-JFK-FRA  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove the Year of the routeId column\n",
    "passengers = pd.read_csv(\"../../data/raw/passengers_w_departuresPerformed(29Nov).csv\")\n",
    "\n",
    "passengers['routeid_2'] = passengers['routeid'].str[5:]\n",
    "passengers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "945a5fea-71e6-40e4-80d8-48749844bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2334701\n",
      "Unique values: 612051\n",
      "Duplicate values: 1722650\n"
     ]
    }
   ],
   "source": [
    "#Lets see the duplicates\n",
    "print(\"Total rows:\", passengers['routeid_2'].count())\n",
    "print(\"Unique values:\", passengers['routeid_2'].nunique())\n",
    "print(\"Duplicate values:\", passengers['routeid_2'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fbfe4-1f1a-48c2-af20-40a477f2b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "So each rows have about 2-3x values.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3fa95b63-497c-48c4-9b7f-2cdb8035e5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size passengers: (2334701, 12)\n",
      "Initial size passengers_2019: (485684, 7)\n",
      "Final size passengers_2019: (304430, 7)\n",
      "Final size passengers: (612051, 13)\n"
     ]
    }
   ],
   "source": [
    "# So now we need to group by routeid and avg the values for averagepayload_lbs, averagefreight_lbs, averagemail_lbs, availableseats, averagepassengers. \n",
    "# We'll also keep the most recent value (year 2019) for aircraftgroup, aircrafttype, aircraftconfiguration, distanceinterval_x500mi, serviceclass\n",
    "# I'll be honest I don't know how to deal with the binary columns to do them in one shot So I'll filter the passengers table to only include 2019 values and then group each df by routeid and then merge them back together\n",
    "print(\"Initial size passengers:\", passengers.shape)\n",
    "\n",
    "# Separating the binary columns and grouping them\n",
    "passengers_2019 = passengers[passengers['routeid'].str.startswith('2019')]\n",
    "passengers_2019 = passengers_2019.drop(['averagepayload_lbs', 'averagefreight_lbs', 'averagemail_lbs', 'availableseats', 'averagepassengers'], axis=1)\n",
    "print(\"Initial size passengers_2019:\", passengers_2019.shape)\n",
    "passengers_2019 = passengers_2019.groupby('routeid_2').agg({'routeid' : 'last', 'aircraftgroup': 'last', 'aircrafttype': 'last', 'aircraftconfiguration': 'last', 'distanceinterval_x500mi': 'last', 'serviceclass': 'last'}).reset_index()\n",
    "passengers_2019 = passengers_2019.drop_duplicates(subset=['routeid_2'], keep='last') #drop duplicate rows\n",
    "\n",
    "print(\"Final size passengers_2019:\", passengers_2019.shape) #just to se if we actually did anything\n",
    "\n",
    "# Delete the binary columns from the passengers table\n",
    "passengers = passengers.drop(['aircraftgroup', 'aircrafttype', 'aircraftconfiguration', 'distanceinterval_x500mi', 'serviceclass'], axis=1)\n",
    "\n",
    "# Merge the route_Id and average the other values\n",
    "passengers.groupby('routeid_2').agg({'routeid' : 'last', 'averagepayload_lbs': 'mean', 'averagefreight_lbs': 'mean', 'averagemail_lbs': 'mean', 'availableseats': 'mean', 'averagepassengers': 'mean'}).reset_index()\n",
    "passengers = passengers.drop_duplicates(subset=['routeid_2'], keep='last') #drop duplicate rows\n",
    "\n",
    "# Add the binary columns back to the passengers table\n",
    "passengers = passengers.merge(passengers_2019, on='routeid_2', how='left')\n",
    "print(\"Final size passengers:\", passengers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ca07e-9c48-4fe8-b915-5042e8795169",
   "metadata": {},
   "source": [
    "We're matching our unique values! DOUBLE BAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "939c39cb-9020-49ef-a925-810bad90a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop our original route_Ids column and rename the routeid_2 column to routeid\n",
    "passengers = passengers.drop(['routeid_x', 'routeid_y'], axis=1)\n",
    "passengers = passengers.rename(columns={'routeid_2': 'routeid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "96966e40-96a2-4e51-ad8a-d99473f12544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns\n",
    "passengers = passengers[['routeid', 'averagepayload_lbs', 'averagefreight_lbs', 'averagemail_lbs', 'availableseats', 'averagepassengers', 'aircraftgroup', 'aircrafttype', 'aircraftconfiguration', 'distanceinterval_x500mi', 'serviceclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "018bae6e-d55f-4096-b489-fb0b49c9e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers.to_csv(\"../../data/raw/passengers_w_departuresPerformed_groupedbyMonth(29Nov).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea84b11-0c61-4f72-8cca-f5a7b2ca1ace",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Keep only relevant rows (Take 2 - The good one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6ccd7-37b1-4530-bcdd-717907a22893",
   "metadata": {},
   "source": [
    "The passengers table is huge, it likely has information on routes that we don't need. Let's slim it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1bd54769-32ec-44cb-85f4-5a97408b1b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612051, 12)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "248502d9-d6fb-4918-b6d0-e35dbac2e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create the route_ID column for flights_sample\n",
    "flights_sample['routeId_op'] = flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Operator - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']\n",
    "flights_sample['routeId_mkt'] = flights_sample['Flight Month'].astype(str) + '-' + flights_sample['Marketer - Unique Carrier Code'] + '-' + flights_sample['Origin Airport (IATA Code)'] + '-' + flights_sample['Destination Airport (IATA Code)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c218a37-cdd1-40e1-9d7d-faacdb048202",
   "metadata": {},
   "source": [
    "Made 2x version, as not sure if the passengers' table is referring to the Operator or the Marketer.. we'll test both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "400d1e74-f06e-46ed-be4f-419b8ecf9463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight Operator\n",
      "Total: 81962\n",
      "In passenger: 81961\n",
      "\n",
      "Flight Marketer\n",
      "Total: 69366\n",
      "In passenger: 53140\n",
      "\n",
      "Passengers Table\n",
      "Total: 612051\n",
      "In Marketer: 53140\n",
      "In Operator: 81961\n"
     ]
    }
   ],
   "source": [
    "# List the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy arrai\n",
    "flight_op = pd.DataFrame()\n",
    "flight_mkt = pd.DataFrame()\n",
    "unique_passengers = pd.DataFrame() \n",
    "\n",
    "flight_op['routeId_op'] = flights_sample['routeId_op'].unique()\n",
    "flight_mkt['routeId_mkt'] = flights_sample['routeId_mkt'].unique()\n",
    "unique_passengers['routeid'] = passengers['routeid'].unique()\n",
    "\n",
    "# Count the number of unique flights_sample['routeId_op'] values that are in the passengers['routeid'] column using the isin() method, ensuring the values are stored in a df, not a numpy array\n",
    "print(\"Flight Operator\")\n",
    "print(\"Total:\", len(flight_op))\n",
    "print(\"In passenger:\", flight_op['routeId_op'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Flight Marketer\")\n",
    "print(\"Total:\", len(flight_mkt))\n",
    "print(\"In passenger:\", flight_mkt['routeId_mkt'].isin(unique_passengers['routeid']).sum())\n",
    "print()\n",
    "print(\"Passengers Table\") #Double tab but just to be sure..\n",
    "print(\"Total:\", len(unique_passengers))\n",
    "print(\"In Marketer:\", unique_passengers['routeid'].isin(flight_mkt['routeId_mkt']).sum())\n",
    "print(\"In Operator:\", unique_passengers['routeid'].isin(flight_op['routeId_op']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c633fe8-e8af-4d8e-97d3-8e9fa1493033",
   "metadata": {},
   "source": [
    "Excellent, we're 100% for Flight Operator. We'll use this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "011bbb9f-9029-4b6a-9d1f-b46e7fdc988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_sample = flights_sample.drop(['routeId_mkt'], axis=1)\n",
    "flights_sample = flights_sample.rename(columns={'routeId_op': 'routeId'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d7191-4f7c-411c-9f3f-b488862dded4",
   "metadata": {},
   "source": [
    "NEXT STEP:\n",
    "\n",
    "Add the passenger enrichment to the rows in flights_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2fd1c4-e8a5-4c56-b0b8-fcc5fff97d77",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0aa1e9-4cba-48ee-81d6-af252126087b",
   "metadata": {},
   "source": [
    "LEAVE FORMATISSUES TO FALSE. There is over 3 million lines, this will lead to problems..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1fb7bc-6a4d-47b2-a7ef-6f9de04592f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataCleaning(passengers, formatIssues=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4748c-3388-4f99-b43d-86eec9b4195f",
   "metadata": {},
   "source": [
    "It's too much to handle.. Before it crashed noticed a significant amount of outliers in the payload/freight/mail columns.. will need to further investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26d1e81-d12e-47e7-a489-9c5261c847c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2334701 entries, 0 to 2334700\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   routeid                  object \n",
      " 1   averagepayload_lbs       float64\n",
      " 2   averagefreight_lbs       float64\n",
      " 3   averagemail_lbs          float64\n",
      " 4   availableseats           float64\n",
      " 5   averagepassengers        float64\n",
      " 6   aircraftgroup            int64  \n",
      " 7   aircrafttype             int64  \n",
      " 8   aircraftconfiguration    int64  \n",
      " 9   distanceinterval_x500mi  int64  \n",
      " 10  serviceclass             object \n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 195.9+ MB\n"
     ]
    }
   ],
   "source": [
    "passengers.info()\n",
    "#passengers.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed8127-f60d-4389-a216-b6173d8ef7c7",
   "metadata": {},
   "source": [
    "Data Types appear GTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b471e92b-a0ef-4027-bf74-08da22b48bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averagepayload_lbs</th>\n",
       "      <th>averagefreight_lbs</th>\n",
       "      <th>averagemail_lbs</th>\n",
       "      <th>availableseats</th>\n",
       "      <th>averagepassengers</th>\n",
       "      <th>aircraftgroup</th>\n",
       "      <th>aircrafttype</th>\n",
       "      <th>aircraftconfiguration</th>\n",
       "      <th>distanceinterval_x500mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "      <td>2.334701e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.255750e+04</td>\n",
       "      <td>7.414158e+03</td>\n",
       "      <td>1.602968e+02</td>\n",
       "      <td>1.016929e+02</td>\n",
       "      <td>7.864157e+01</td>\n",
       "      <td>5.508221e+00</td>\n",
       "      <td>6.054888e+02</td>\n",
       "      <td>1.213319e+00</td>\n",
       "      <td>2.634128e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.102180e+04</td>\n",
       "      <td>2.690791e+04</td>\n",
       "      <td>1.481311e+03</td>\n",
       "      <td>8.263260e+01</td>\n",
       "      <td>6.990261e+01</td>\n",
       "      <td>1.540163e+00</td>\n",
       "      <td>1.666219e+02</td>\n",
       "      <td>5.267736e-01</td>\n",
       "      <td>2.477123e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.350000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.140000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.444600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.780000e+01</td>\n",
       "      <td>6.511111e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.310000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.340000e+04</td>\n",
       "      <td>2.036279e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000e+02</td>\n",
       "      <td>1.324348e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.910000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.500000e+05</td>\n",
       "      <td>4.614478e+05</td>\n",
       "      <td>2.425470e+05</td>\n",
       "      <td>7.369000e+03</td>\n",
       "      <td>5.290000e+02</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.900000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.100000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       averagepayload_lbs  averagefreight_lbs  averagemail_lbs  \\\n",
       "count        2.334701e+06        2.334701e+06     2.334701e+06   \n",
       "mean         4.255750e+04        7.414158e+03     1.602968e+02   \n",
       "std          5.102180e+04        2.690791e+04     1.481311e+03   \n",
       "min          0.000000e+00        0.000000e+00     0.000000e+00   \n",
       "25%          1.350000e+04        0.000000e+00     0.000000e+00   \n",
       "50%          3.444600e+04        0.000000e+00     0.000000e+00   \n",
       "75%          4.340000e+04        2.036279e+02     0.000000e+00   \n",
       "max          5.500000e+05        4.614478e+05     2.425470e+05   \n",
       "\n",
       "       availableseats  averagepassengers  aircraftgroup  aircrafttype  \\\n",
       "count    2.334701e+06       2.334701e+06   2.334701e+06  2.334701e+06   \n",
       "mean     1.016929e+02       7.864157e+01   5.508221e+00  6.054888e+02   \n",
       "std      8.263260e+01       6.990261e+01   1.540163e+00  1.666219e+02   \n",
       "min      0.000000e+00       0.000000e+00   0.000000e+00  1.000000e+01   \n",
       "25%      9.000000e+00       4.000000e+00   6.000000e+00  6.140000e+02   \n",
       "50%      7.780000e+01       6.511111e+01   6.000000e+00  6.310000e+02   \n",
       "75%      1.600000e+02       1.324348e+02   6.000000e+00  6.910000e+02   \n",
       "max      7.369000e+03       5.290000e+02   8.000000e+00  8.900000e+02   \n",
       "\n",
       "       aircraftconfiguration  distanceinterval_x500mi  \n",
       "count           2.334701e+06             2.334701e+06  \n",
       "mean            1.213319e+00             2.634128e+00  \n",
       "std             5.267736e-01             2.477123e+00  \n",
       "min             1.000000e+00             1.000000e+00  \n",
       "25%             1.000000e+00             1.000000e+00  \n",
       "50%             1.000000e+00             2.000000e+00  \n",
       "75%             1.000000e+00             3.000000e+00  \n",
       "max             4.000000e+00             2.100000e+01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c40ce07-76e8-40ab-9d59-e97364db328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2334701, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301f8c7-92b6-401d-9c92-74f296aeffe2",
   "metadata": {},
   "source": [
    "# Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cc5b96-588d-45f9-9be1-45cf28343175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#passengers.to_csv('../../data/processed/flights_enrichment_passengers.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b54f3-ab98-444e-bd16-50322e2096c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
